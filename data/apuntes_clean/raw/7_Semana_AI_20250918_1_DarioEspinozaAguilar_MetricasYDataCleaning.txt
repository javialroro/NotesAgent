Apuntes Semana 7 - 18/09/2025
1stDar´ıo Espinoza Aguilar
2020109109
Computer Engenieering
darioespinoza477@estudiantec.cr
Abstract —Este documento corresponde a los apuntes de la
clase del 18 de septiembre de 2025, donde se repasan los conceptos
de m ´etricas y f ´ormulas para evaluar los modelos. Adem ´as, se hace
un repaso del proceso de preparaci ´on y procesamiento de datos
antes de poder entrenar el modelo.
Index Terms —M ´etricas, data cleaning, procesamiento de datos,
datasets
I. I NTRODUCCI ´ON
Se mencion ´o que se iba a dejar la Tarea 2 la otra semana
y el proyecto 1 la semana que le sigue. Adem ´as, nos dio la
invitaci ´on al evento de Ingenier ´ıa para lo que quiera asistir.
En la parte de noticias, se mencion ´o que Xbox Gaming
esta desarrollado un IA para desarrollar juegos viejos, m ´as
que un desarrollador es un porteador de juego viejos para que
puedan ser jugables.
El profe menciona que se lanz ´o un protocolo nuevo para
pago a trav ´es de agentes. El protocolo es AP2, fue lanzado
por Google y lo que se busca es que los pagos por medios
electr ´onicos se puedan realizar sin necesidad de intervenci ´on
humana. Menciono la posibilidad de hacer pasant ´ıa en la
empresa donde ´el trabaja.
Se hablo de las pr ´oximas evaluaciones que vamos a tener, el
profesor menciono que la mayor ´ıa de las tareas programadas
ya sean proyectos o tareas van a ser de modelos clasificatorios
ya que tiene afinidad por ellos y que se van a tener tareas de
investigaci ´on.
II. R EPASO DE M´ETRICAS
Son las m ´etricas asociadas a un modelo que nos indica el
rendimiento de un modelo predictivo. La forma m ´as objetiva
de evaluar y comparar un modelo. En todos los modelos que
se sacan siempre hay m ´etricas o benchmarks que nos indican
que tan bueno es el modelo.
Se repaso lo que es la matriz de confusi ´on. Que de los
algoritmos de clasificaci ´on tenemos 2 etiquetas se pueden ver
como positivo y negativo, y de esas 2 etiquetas se pueden
tener 4 4 posibles valores que la matriz de confusi ´on nos
ayuda a visualizar esos valores. En esta matriz se tienen los
Target Class que es la etiqueta tenemos en el dataset y el
predicted class que es la predicci ´on de nuestro modelo. Los
cuatros combinaciones•TP: True positive
•TN: True negative
•FP: False positive
•FN: False negative
A partir de estos se pueden hacer varias combinaciones
para calcular ciertas m ´etricas
1) Accuracy: Clasificaci ´on correcta entre todos los intentos.
La f´ormula es la siguiente:
Accuracy =TP+TN
TP+TN +FP +FN
Es´util cuando los errores por clase son igual de importantes.
Otorga importancia igual a todas las claases.
2) Precision: Mide los errores tipo 1 (FP). Tasa de predic-
ciones positivas correctas entre todas las predicciones positi-
vas.
Precision =TP
TP+FP
3) Recall: Mide los errores de tipo 2 (FN). Tasa de
predicciones correctas entre todos los ejemplos positivos del
conjunto de datos.
Recall =TP
TP+FN
4) F1-Score: Esta es un m ´etrica que contempla ambos
errores. Com ´unmente utilizada en problemas de clasificaci ´on,
especialemnte cuando tenemos desequelibrio de clases.
F1 =2·precision ·recall
precision +recall
A. ROC (Receiver Operating Characteristic)
El´area bajo la curva siempre tiene que ser >0.5. Si es = 5
lo que vamos a tener es un random clasifier, es un clasificador
aleatorio. Si es cada vez mayor a 0.5 el modelo va siendo
mejor.
III. R ESPASO DE PROCESAMIENTO DE DATOS
En la pr ´actica podemos tener ciertos problemas con nuestros
datos:
•Incompletitud: valores faltantes en atributos importantes
•Inexactitud o ruido: errores y valores at ´ıpico en las
transacciones
•Inconsistencia: discrepancia en lo c ´odigo de departamen-
tos o categor ´ıa

A. ¿Por qu ´e los datos pueden ser inexactos?
•Instrumentos de recolecci ´on de datos defectuosos.
•Errores humanos o computacionales en la entrada de
datos.
•Usuarios que ingresan valores falsos para campos obli-
gatorios.
–Conocido como datos faltantes disfrazados .
•Inconsistencia en convenciones de nombres, c ´odigos o
formatos.
•Tuplas duplicadas que requieren procesos de data clean-
ing.
B. ¿Por qu ´e los datos pueden estar incompletos?
•Atributos de inter ´es no siempre est ´an disponibles
•No se incluyen porque no se consideraron importantes en
el momento de la entrada
•Datos relevantes no se registran por malentendidos o
fallos del equipo
•Datos inconsistentes con otros registros pueden ser elim-
inados
•Historial o modificaciones de datos pasados pueden no
haberse registrado
•Valores faltantes en atributos claves pueden necesitar ser
inferidos
C. ¿Por qu ´e los datos pueden ser inconsistentes?
•Diferencias en convenciones de nombres o c ´odigos usa-
dos para clasificar elementos
•Formatos de entrada distintos para un mismo atributo
•Conflictos entre bases de datos o sistemas que manejan
el
•Errores al integrar datos de m ´ultiples fuentes het-
erog´eneas
•Actualizaciones parciales o incorrectas que dejan reg-
istros contradictorios
D. Principales tareas en el preprocesamiento de datos
•Data Cleaning Eliminaci ´on de ruido, correcci ´on de in-
consistencias, tratamiento de valores faltantes
•Data Integration Combinaci ´on de datos de m ´ultiples
fuentes heterog ´eneas en un repositorio coherente
•Data Reduction Reducci ´on de volumen mediante se-
lecci ´on de atributos, reducci ´on de dimensionalidad o
discretizaci ´on
•Data Transformation Normalizaci ´on, estandarizaci ´on,
agregaci ´on, construcci ´on de nuevas variables
•Data Discretization Transformaci ´on de atributos contin-
uos en atributos categ ´oricos
1) Data cleaning (missing values):
•Ignorar tuplas con valores faltantes (riesgo si la perdida
de datos es significtiva)
•Completar manualmente los valores (costoso y poco
pr´actico en grandes datasets)
•Usar un valor global constante.
•Rellenar con la media (normal), mediana o moda•Inferir valores mediante modelos estadistico o de ML
(regresi ´on, k-NN, ´arboles de decisi ´on)
2) Data Cleaning (Noisy Data):
•Agrupar valores en intervalos(bins).
•Se puede utilizar con datos muy ruidosos, se reemplaza el
valor por: la media del bin, la mediana del bin, el borde
m´as cercano del bin.
3) Data Integration (Redundancy Handling):
•Se ajusta una funci ´on matem ´atica (lineal o no lineal) para
suavizar el ruido de los datos.
•Aplicar t ´ecnicas de filtrado para suavizar fluctuaciones,
se puede utilizar la media m ´ovil (utilizar los ´ultimos 7
elementos para ir calculando la media).