Apuntes de la Clase Semana 7 2025
Curso de Inteligencia Artificial
Rafael Vargas Solis
Apuntes del 16 de Setiembre de 2025
Resumen —Este documento presenta un resumen de los temas
clave abordados en la clase de Inteligencia Artificial del 16
de setiembre de 2025. Comienza describiendo las diferencias
fundamentales entre la regresi ´on lineal y la regresi ´on log ´ıstica, as ´ı
como las t ´ecnicas comunes para el manejo de valores at ´ıpicos y las
estrategias para enfrentar el sesgo y la varianza en los modelos de
aprendizaje autom ´atico. Posteriormente, se discuten las m ´etricas
de evaluaci ´on tanto para clasificaci ´on como para regresi ´on, in-
cluyendo la matriz de confusi ´on, precisi ´on, exhaustividad (recall),
F1-score, curva ROC y el ´area bajo la curva (AUC), apoyadas
en ejemplos pr ´acticos. Finalmente, el documento resalta los
problemas m ´as frecuentes en la calidad de los datos —como
la incompletitud, la inexactitud y la inconsistencia— y enfatiza
la importancia de las tareas de preprocesamiento, tales como
limpieza, integraci ´on, reducci ´on, transformaci ´on y discretizaci ´on,
para garantizar el desarrollo de modelos predictivos robustos y
confiables.
Index Terms —Inteligencia Artificial, Aprendizaje Autom ´atico,
Regresi ´on, Valores At ´ıpicos, Sesgo, Varianza, M ´etricas de Eval-
uaci´on, Matriz de Confusi ´on, ROC, AUC, Preprocesamiento de
Datos
I. P REGUNTAS DEL QUIZ
1. ¿Cu ´al es la diferencia entre regresi ´on lineal y re-
gresi ´on log ´ıstica?
Laregresi ´on lineal se utiliza para predecir variables con-
tinuas, ajustando una recta que minimiza el error cuadr ´atico
medio. Por ejemplo, estimar el precio de una vivienda seg ´un
su tama ˜no.
En cambio, la regresi ´on log ´ıstica se aplica a problemas
de clasificaci ´on, donde la variable dependiente es categ ´orica
(binaria en la mayor ´ıa de casos). Utiliza la funci ´on sigmoide
para mapear los valores de entrada en probabilidades entre 0y
1. Ejemplo: predecir si un estudiante aprobar ´a o no un curso.
2. Describa tres t ´ecnicas para el tratamiento de datos
sobresalientes (outliers).
Los outliers o valores at ´ıpicos son observaciones que se
alejan significativamente del patr ´on general de los datos y
pueden afectar la precisi ´on de los modelos predictivos. Existen
diversas estrategias para tratarlos, entre las cuales destacan:
•Eliminaci ´on:Consiste en remover los outliers identifi-
cados cuando se determina que son producto de errores
de medici ´on, registros defectuosos o inconsistencias en
la recolecci ´on de datos. Esta t ´ecnica debe aplicarse con
cautela para no eliminar informaci ´on valiosa.
•Transformaci ´on de variables: Aplicar funciones
matem ´aticas como logaritmos, ra ´ıces cuadradas o escal-
ados que reduzcan la magnitud de los valores extremos.De esta manera, se disminuye su influencia en la varianza
del modelo y se mejora la distribuci ´on de los datos.
•Winsorizaci ´on (recorte): Sustituir los valores at ´ıpicos
por valores m ´as cercanos dentro de un rango definido,
usualmente basado en percentiles (por ejemplo, 1% y
99%). Esta t ´ecnica conserva la estructura general de los
datos y evita que los valores extremos distorsionen los
resultados.
3. Mencione dos t ´ecnicas para evitar un alto sesgo y dos
para evitar alta varianza.
En el aprendizaje autom ´atico, es fundamental lograr un
equilibrio entre sesgo yvarianza para obtener modelos con
buena capacidad de generalizaci ´on. A continuaci ´on, se de-
scriben algunas t ´ecnicas para abordar ambos problemas:
Para reducir sesgo (underfitting):
•Incrementar la complejidad del modelo: Utilizar mod-
elos m ´as sofisticados, como polinomiales en lugar de
lineales, redes neuronales m ´as profundas o algoritmos no
lineales, permite capturar relaciones m ´as complejas entre
las variables.
•Incorporar nuevas variables o caracter ´ısticas: Me-
diante t ´ecnicas de feature engineering , se pueden in-
cluir atributos relevantes que enriquezcan la informaci ´on
disponible, mejorando as ´ı la capacidad predictiva del
modelo.
Para reducir varianza (overfitting):
•Aplicar regularizaci ´on: M´etodos como L1 (Lasso) y
L2 (Ridge) a ˜naden penalizaciones a los coeficientes del
modelo, limitando su magnitud y evitando que el modelo
se ajuste excesivamente a los datos de entrenamiento.
•Aumentar los datos o usar t ´ecnicas de ensamble:
Incrementar el tama ˜no del conjunto de entrenamiento o
aplicar m ´etodos como bagging yrandom forest mejora la
estabilidad del modelo y reduce la sensibilidad al ruido
de los datos.
4. ¿Cu ´al es la derivada de la funci ´on sigmoide σ(x) =
1
1+e−x?
La funci ´on sigmoide se define como:
σ(x) =1
1 +e−x(1)
Su derivada es:
σ′(x) =σ(x) (1−σ(x)) (2)

II. M ´ETRICAS
Son medidas que se utilizan para indicar el rendimiento
de un modelo predictivo. Constituyen la forma m ´as objetiva
de evaluar y comparar modelos de aprendizaje autom ´atico,
permitiendo determinar qu ´e tan bien se ajustan a los datos de
entrenamiento y, sobre todo, qu ´e tan bien generalizan a datos
no vistos.
Asimismo, se emplean benchmarks , que son conjuntos de
datos o pruebas estandarizadas utilizadas en la comunidad
cient ´ıfica para comparar de manera justa el desempe ˜no de
distintos modelos. El uso de benchmarks permite establecer
un est ´andar de referencia que facilita la reproducibilidad y la
comparaci ´on entre diferentes enfoques.
En general, las m ´etricas pueden dividirse en:
•M´etricas de clasificaci ´on: accuracy, precision, recall, F1-
score, ROC y AUC.
•M´etricas de regresi ´on: error cuadr ´atico medio (MSE),
error absoluto medio (MAE) o coeficiente de determi-
naci´on (R2).
III. M ATRIZ DE CONFUSI ´ON
Lamatriz de confusi ´onorganiza los resultados de un modelo
de clasificaci ´on en funci ´on de las predicciones realizadas y las
clases reales. Se definen cuatro componentes:
•True Positive (TP) : positivos correctamente clasificados.
•False Positive (FP) : negativos clasificados incorrecta-
mente como positivos (error tipo I).
•True Negative (TN) : negativos correctamente clasifica-
dos.
•False Negative (FN) : positivos clasificados incorrecta-
mente como negativos (error tipo II).
En problemas multiclase, la matriz puede extenderse a
N×N. Un clasificador ideal concentra todos los valores en
la diagonal principal.
Fig. 1. Ejemplo de matriz de confusi ´on en clasificaci ´on binaria.
IV. M ´ETRICAS CL´ASICAS
A partir de la matriz de confusi ´on se derivan las m ´etricas
m´as utilizadas:A. Accuracy
Accuracy =TP+TN
TP+TN +FP+FN(3)
Mide la proporci ´on de predicciones correctas. Es ´util en datos
balanceados, pero enga ˜nosa en clases desbalanceadas.
B. Precisi ´on
Precision =TP
TP+FP(4)
Indica qu ´e proporci ´on de predicciones positivas fueron correc-
tas. Relevante cuando los falsos positivos son costosos.
C. Recall (Sensibilidad)
Recall =TP
TP+FN(5)
Mide la capacidad del modelo para identificar correctamente
los positivos. Importante en contextos donde los falsos nega-
tivos son cr ´ıticos.
D. F1-Score
F1 =2·Precision ·Recall
Precision +Recall(6)
Es la media arm ´onica entre precisi ´on y recall, usada en casos
de desbalance de clases.
V. C ASO DE ESTUDIO
Se evalu ´o un modelo de detecci ´on de c ´ancer con 1000
pacientes.
•Clase positiva: 30 pacientes con c ´ancer.
•Clase negativa: 970 pacientes sin c ´ancer.
Matriz de confusi ´on:
C´ancer No c ´ancer
C´ancer 25 (TP) 20 (FP)
No c ´ancer 5 (FN) 950 (TN)
Resultados:
•Accuracy:25+950
1000= 97.5%
•Recall:25
25+5= 83.3%
•Precisi ´on:25
25+20= 55%
•F1-Score:2·0.55·0.833
0.55+0 .833≈66.2%
A pesar del alto valor de accuracy, las m ´etricas muestran
limitaciones en la detecci ´on de la clase positiva.
VI. M ´ETRICAS AVANZADAS
A. Curva ROC
La curva ROC ( Receiver Operating Characteristic ) mues-
tra el desempe ˜no de un clasificador binario para distintos
umbrales. Representa la Tasa de Verdaderos Positivos (TPR)
frente a la Tasa de Falsos Positivos (FPR).

Fig. 2. Ejemplo de curva ROC y c ´alculo de AUC.
B.´Area Bajo la Curva (AUC)
El AUC mide el ´area bajo la curva ROC:
•AUC = 0.5: clasificador aleatorio.
•AUC cercano a 1: modelo con gran poder de discrimi-
naci´on.
VII. P ROCESAMIENTO DE DATOS
A. Problemas encontrados en la calidad de datos
En escenarios reales, los datos suelen presentar problemas
que afectan directamente la efectividad de los algoritmos de
miner ´ıa y aprendizaje autom ´atico. Los principales son:
•Incompletitud: valores faltantes en atributos importantes.
Ejemplo: si un producto estaba en oferta y no se registr ´o
la variable.
•Inexactitud o ruido: errores de medici ´on, valores
at´ıpicos o entradas an ´omalas en transacciones.
•Inconsistencia: discrepancias en nombres, c ´odigos
o formatos. Ejemplo: fechas almacenadas como
DD/MM/AAAA en una base de datos y como
MM-DD-YYYY en otra.
Un caso ilustrativo es la recolecci ´on de datos m ´edicos: en la
medici ´on de presi ´on sangu ´ınea, un valor faltante no implica
que el registro deba eliminarse, ya que otras caracter ´ısticas
(edad, peso, historial cl ´ınico) s ´ı aportan informaci ´on valiosa.
Esto demuestra que los datasets requieren preprocesamiento
antes de aplicar t ´ecnicas de miner ´ıa o aprendizaje.
B. Causas de datos defectuosos
•Instrumentos de recolecci ´on defectuosos.
•Errores humanos o computacionales en la entrada de
datos.
•Valores falsos en campos obligatorios (ejemplo: fecha por
defecto “1 de enero” para ocultar cumplea ˜nos), conocidos
como datos faltantes disfrazados .•Inconsistencias en convenciones de nombres, c ´odigos o
formatos.
•Registros duplicados que requieren procesos de data
cleaning .
C. Causas de incompletitud
•Atributos de inter ´es no siempre disponibles o considera-
dos irrelevantes en el momento de captura.
•Fallos t ´ecnicos o malentendidos durante la recolecci ´on.
•Eliminaci ´on de registros por inconsistencias.
•Ausencia de historial o modificaciones no registradas.
•Valores faltantes en atributos clave que deben ser inferi-
dos.
D. Causas de inconsistencias
•Diferencias en convenciones de nombres o c ´odigos.
•Formatos de entrada distintos para un mismo atributo.
•Conflictos entre bases de datos heterog ´eneas.
•Errores en la integraci ´on de fuentes m ´ultiples.
•Actualizaciones parciales que dejan registros contradic-
torios.
E. Principales tareas en el preprocesamiento
•Data cleaning: eliminaci ´on de ruido, correcci ´on de in-
consistencias y tratamiento de valores faltantes.
•Data integration: combinaci ´on de datos provenientes de
m´ultiples fuentes heterog ´eneas en un repositorio unifi-
cado.
•Data reduction: reducci ´on de volumen mediante se-
lecci ´on de atributos, reducci ´on de dimensionalidad o
discretizaci ´on.
•Data transformation: normalizaci ´on, estandarizaci ´on,
agregaci ´on y construcci ´on de nuevas variables.
•Data discretization: transformaci ´on de atributos contin-
uos en categor ´ıas o intervalos.
F . Data Cleaning: Tratamiento de valores faltantes y ruido
1) Valores faltantes:
•Ignorar tuplas con valores faltantes (riesgoso si se pierde
mucha informaci ´on).
•Completar manualmente (costoso en grandes datasets).
•Usar un valor global constante (ej. “desconocido”).
•Rellenar con la media, mediana o moda, tambi ´en por
clase.
•Inferir valores mediante modelos estad ´ısticos o de ML
(regresi ´on,k-NN, ´arboles de decisi ´on).
2) Binning: Binning agrupa valores en intervalos ( bins) y
reemplaza cada valor por:
•La media del bin.
•La mediana del bin.
•El borde m ´as cercano del bin.
Ejemplo: salarios ruidosos [2950, 3000, 3020, 8000]. El bin
(2900–3100) se reemplaza por la media (2990), mientras que
8000 queda como posible outlier.

3) Suavizado de ruido:
•Ajustar una funci ´on matem ´atica (lineal o no lineal) para
suavizar fluctuaciones. Ejemplo: regresi ´on lineal en ven-
tas mensuales.
•Aplicar t ´ecnicas de filtrado como la media m ´ovil:
MA 7(t) =1
76X
i=0xt−i
donde xtes el valor en el d ´ıat. Esto genera una curva
suavizada que refleja la tendencia real.
G. Data Integration: Manejo de redundancia
La misma informaci ´on puede estar registrada varias veces
o con diferencias. Ejemplo: un cliente como “Juan P ´erez”
en una base de datos y “J. A. P ´erez” en otra. Se aplican
pruebas estad ´ısticas como la chi-cuadrado (χ2) para detectar
redundancia o asociaciones entre variables categ ´oricas:
H0:P(Ai∩Bj) =P(Ai)P(Bj)
Siχ2
calculado ≤χ2
α,d f, se acepta la hip ´otesis de independencia.
REFERENCES
[1] A. Burkov, The Hundred-Page Machine Learning Book . Andriy Burkov,
2019. [Online]. Available: https://themlbook.com/