Apuntes Semana 7 - 18/09/2025
1stDario Espinoza Aguilar
2020109109
Computer Engenieering
darioespinoza477@estudiantec.cr
Abstract —Este documento corresponde a los apuntes de la
clase del 18 de septiembre de 2025, donde se repasan los conceptos
de metricas y formulas para evaluar los modelos. Ademas, se hace
un repaso del proceso de preparacion y procesamiento de datos
antes de poder entrenar el modelo.
Index Terms —Metricas, data cleaning, procesamiento de datos,
datasets
I. I NTRODUCCION
Se menciono que se iba a dejar la Tarea 2 la otra semana
y el proyecto 1 la semana que le sigue. Ademas, nos dio la
invitacion al evento de Ingenieria para lo que quiera asistir.
En la parte de noticias, se menciono que Xbox Gaming
esta desarrollado un IA para desarrollar juegos viejos, mas
que un desarrollador es un porteador de juego viejos para que
puedan ser jugables.
El profe menciona que se lanzo un protocolo nuevo para
pago a traves de agentes. El protocolo es AP2, fue lanzado
por Google y lo que se busca es que los pagos por medios
electronicos se puedan realizar sin necesidad de intervencion
humana. Menciono la posibilidad de hacer pasantia en la
empresa dondeel trabaja.
Se hablo de las proximas evaluaciones que vamos a tener, el
profesor menciono que la mayoria de las tareas programadas
ya sean proyectos o tareas van a ser de modelos clasificatorios
ya que tiene afinidad por ellos y que se van a tener tareas de
investigacion.
II. R EPASO DE METRICAS
Son las metricas asociadas a un modelo que nos indica el
rendimiento de un modelo predictivo. La forma mas objetiva
de evaluar y comparar un modelo. En todos los modelos que
se sacan siempre hay metricas o benchmarks que nos indican
que tan bueno es el modelo.
Se repaso lo que es la matriz de confusion. Que de los
algoritmos de clasificacion tenemos 2 etiquetas se pueden ver
como positivo y negativo, y de esas 2 etiquetas se pueden
tener 4 4 posibles valores que la matriz de confusion nos
ayuda a visualizar esos valores. En esta matriz se tienen los
Target Class que es la etiqueta tenemos en el dataset y el
predicted class que es la prediccion de nuestro modelo. Los
cuatros combinaciones•TP: True positive
•TN: True negative
•FP: False positive
•FN: False negative
A partir de estos se pueden hacer varias combinaciones
para calcular ciertas metricas
1) Accuracy: Clasificacion correcta entre todos los intentos.
La formula es la siguiente:
Accuracy =TP+TN
TP+TN +FP +FN
Esutil cuando los errores por clase son igual de importantes.
Otorga importancia igual a todas las claases.
2) Precision: Mide los errores tipo 1 (FP). Tasa de predic-
ciones positivas correctas entre todas las predicciones positi-
vas.
Precision =TP
TP+FP
3) Recall: Mide los errores de tipo 2 (FN). Tasa de
predicciones correctas entre todos los ejemplos positivos del
conjunto de datos.
Recall =TP
TP+FN
4) F1-Score: Esta es un metrica que contempla ambos
errores. Comunmente utilizada en problemas de clasificacion,
especialemnte cuando tenemos desequelibrio de clases.
F1 =2·precision ·recall
precision +recall
A. ROC (Receiver Operating Characteristic)
Elarea bajo la curva siempre tiene que ser >0.5. Si es = 5
lo que vamos a tener es un random clasifier, es un clasificador
aleatorio. Si es cada vez mayor a 0.5 el modelo va siendo
mejor.
III. R ESPASO DE PROCESAMIENTO DE DATOS
En la practica podemos tener ciertos problemas con nuestros
datos:
•Incompletitud: valores faltantes en atributos importantes
•Inexactitud o ruido: errores y valores atipico en las
transacciones
•Inconsistencia: discrepancia en lo codigo de departamen-
tos o categoria

A. ¿Por que los datos pueden ser inexactos?
•Instrumentos de recoleccion de datos defectuosos.
•Errores humanos o computacionales en la entrada de
datos.
•Usuarios que ingresan valores falsos para campos obli-
gatorios.
–Conocido como datos faltantes disfrazados .
•Inconsistencia en convenciones de nombres, codigos o
formatos.
•Tuplas duplicadas que requieren procesos de data clean-
ing.
B. ¿Por que los datos pueden estar incompletos?
•Atributos de interes no siempre estan disponibles
•No se incluyen porque no se consideraron importantes en
el momento de la entrada
•Datos relevantes no se registran por malentendidos o
fallos del equipo
•Datos inconsistentes con otros registros pueden ser elim-
inados
•Historial o modificaciones de datos pasados pueden no
haberse registrado
•Valores faltantes en atributos claves pueden necesitar ser
inferidos
C. ¿Por que los datos pueden ser inconsistentes?
•Diferencias en convenciones de nombres o codigos usa-
dos para clasificar elementos
•Formatos de entrada distintos para un mismo atributo
•Conflictos entre bases de datos o sistemas que manejan
el
•Errores al integrar datos de multiples fuentes het-
erogeneas
•Actualizaciones parciales o incorrectas que dejan reg-
istros contradictorios
D. Principales tareas en el preprocesamiento de datos
•Data Cleaning Eliminacion de ruido, correccion de in-
consistencias, tratamiento de valores faltantes
•Data Integration Combinacion de datos de multiples
fuentes heterogeneas en un repositorio coherente
•Data Reduction Reduccion de volumen mediante se-
leccion de atributos, reduccion de dimensionalidad o
discretizacion
•Data Transformation Normalizacion, estandarizacion,
agregacion, construccion de nuevas variables
•Data Discretization Transformacion de atributos contin-
uos en atributos categoricos
1) Data cleaning (missing values):
•Ignorar tuplas con valores faltantes (riesgo si la perdida
de datos es significtiva)
•Completar manualmente los valores (costoso y poco
practico en grandes datasets)
•Usar un valor global constante.
•Rellenar con la media (normal), mediana o moda•Inferir valores mediante modelos estadistico o de ML
(regresion, k-NN, ´arboles de decision)
2) Data Cleaning (Noisy Data):
•Agrupar valores en intervalos(bins).
•Se puede utilizar con datos muy ruidosos, se reemplaza el
valor por: la media del bin, la mediana del bin, el borde
mas cercano del bin.
3) Data Integration (Redundancy Handling):
•Se ajusta una funcion matematica (lineal o no lineal) para
suavizar el ruido de los datos.
•Aplicar tecnicas de filtrado para suavizar fluctuaciones,
se puede utilizar la media movil (utilizar losultimos 7
elementos para ir calculando la media).