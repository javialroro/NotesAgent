Apuntes de la Clase Semana 7 2025
Curso de Inteligencia Artificial
Rafael Vargas Solis
Apuntes del 16 de Setiembre de 2025
Resumen —Este documento presenta un resumen de los temas
clave abordados en la clase de Inteligencia Artificial del 16
de setiembre de 2025. Comienza describiendo las diferencias
fundamentales entre la regresion lineal y la regresion logistica, asi
como las tecnicas comunes para el manejo de valores atipicos y las
estrategias para enfrentar el sesgo y la varianza en los modelos de
aprendizaje automatico. Posteriormente, se discuten las metricas
de evaluacion tanto para clasificacion como para regresion, in-
cluyendo la matriz de confusion, precision, exhaustividad (recall),
F1-score, curva ROC y elarea bajo la curva (AUC), apoyadas
en ejemplos practicos. Finalmente, el documento resalta los
problemas mas frecuentes en la calidad de los datos —como
la incompletitud, la inexactitud y la inconsistencia— y enfatiza
la importancia de las tareas de preprocesamiento, tales como
limpieza, integracion, reduccion, transformacion y discretizacion,
para garantizar el desarrollo de modelos predictivos robustos y
confiables.
Index Terms —Inteligencia Artificial, Aprendizaje Automatico,
Regresion, Valores Atipicos, Sesgo, Varianza, Metricas de Eval-
uacion, Matriz de Confusion, ROC, AUC, Preprocesamiento de
Datos
I. P REGUNTAS DEL QUIZ
1. ¿Cual es la diferencia entre regresion lineal y re-
gresion logistica?
Laregresion lineal se utiliza para predecir variables con-
tinuas, ajustando una recta que minimiza el error cuadratico
medio. Por ejemplo, estimar el precio de una vivienda segun
su tamaño.
En cambio, la regresion logistica se aplica a problemas
de clasificacion, donde la variable dependiente es categorica
(binaria en la mayoria de casos). Utiliza la funcion sigmoide
para mapear los valores de entrada en probabilidades entre 0y
1. Ejemplo: predecir si un estudiante aprobara o no un curso.
2. Describa tres tecnicas para el tratamiento de datos
sobresalientes (outliers).
Los outliers o valores atipicos son observaciones que se
alejan significativamente del patron general de los datos y
pueden afectar la precision de los modelos predictivos. Existen
diversas estrategias para tratarlos, entre las cuales destacan:
•Eliminacion:Consiste en remover los outliers identifi-
cados cuando se determina que son producto de errores
de medicion, registros defectuosos o inconsistencias en
la recoleccion de datos. Esta tecnica debe aplicarse con
cautela para no eliminar informacion valiosa.
•Transformacion de variables: Aplicar funciones
matematicas como logaritmos, raices cuadradas o escal-
ados que reduzcan la magnitud de los valores extremos.De esta manera, se disminuye su influencia en la varianza
del modelo y se mejora la distribucion de los datos.
•Winsorizacion (recorte): Sustituir los valores atipicos
por valores mas cercanos dentro de un rango definido,
usualmente basado en percentiles (por ejemplo, 1% y
99%). Esta tecnica conserva la estructura general de los
datos y evita que los valores extremos distorsionen los
resultados.
3. Mencione dos tecnicas para evitar un alto sesgo y dos
para evitar alta varianza.
En el aprendizaje automatico, es fundamental lograr un
equilibrio entre sesgo yvarianza para obtener modelos con
buena capacidad de generalizacion. A continuacion, se de-
scriben algunas tecnicas para abordar ambos problemas:
Para reducir sesgo (underfitting):
•Incrementar la complejidad del modelo: Utilizar mod-
elos mas sofisticados, como polinomiales en lugar de
lineales, redes neuronales mas profundas o algoritmos no
lineales, permite capturar relaciones mas complejas entre
las variables.
•Incorporar nuevas variables o caracteristicas: Me-
diante tecnicas de feature engineering , se pueden in-
cluir atributos relevantes que enriquezcan la informacion
disponible, mejorando asi la capacidad predictiva del
modelo.
Para reducir varianza (overfitting):
•Aplicar regularizacion: Metodos como L1 (Lasso) y
L2 (Ridge) añaden penalizaciones a los coeficientes del
modelo, limitando su magnitud y evitando que el modelo
se ajuste excesivamente a los datos de entrenamiento.
•Aumentar los datos o usar tecnicas de ensamble:
Incrementar el tamaño del conjunto de entrenamiento o
aplicar metodos como bagging yrandom forest mejora la
estabilidad del modelo y reduce la sensibilidad al ruido
de los datos.
4. ¿Cual es la derivada de la funcion sigmoide σ(x) =
1
1+e−x?
La funcion sigmoide se define como:
σ(x) =1
1 +e−x(1)
Su derivada es:
σ′(x) =σ(x) (1−σ(x)) (2)

II. METRICAS
Son medidas que se utilizan para indicar el rendimiento
de un modelo predictivo. Constituyen la forma mas objetiva
de evaluar y comparar modelos de aprendizaje automatico,
permitiendo determinar que tan bien se ajustan a los datos de
entrenamiento y, sobre todo, que tan bien generalizan a datos
no vistos.
Asimismo, se emplean benchmarks , que son conjuntos de
datos o pruebas estandarizadas utilizadas en la comunidad
cientifica para comparar de manera justa el desempeño de
distintos modelos. El uso de benchmarks permite establecer
un estandar de referencia que facilita la reproducibilidad y la
comparacion entre diferentes enfoques.
En general, las metricas pueden dividirse en:
•Metricas de clasificacion: accuracy, precision, recall, F1-
score, ROC y AUC.
•Metricas de regresion: error cuadratico medio (MSE),
error absoluto medio (MAE) o coeficiente de determi-
nacion (R2).
III. M ATRIZ DE CONFUSION
Lamatriz de confusionorganiza los resultados de un modelo
de clasificacion en funcion de las predicciones realizadas y las
clases reales. Se definen cuatro componentes:
•True Positive (TP) : positivos correctamente clasificados.
•False Positive (FP) : negativos clasificados incorrecta-
mente como positivos (error tipo I).
•True Negative (TN) : negativos correctamente clasifica-
dos.
•False Negative (FN) : positivos clasificados incorrecta-
mente como negativos (error tipo II).
En problemas multiclase, la matriz puede extenderse a
N×N. Un clasificador ideal concentra todos los valores en
la diagonal principal.
Fig. 1. Ejemplo de matriz de confusion en clasificacion binaria.
IV. METRICAS CLASICAS
A partir de la matriz de confusion se derivan las metricas
mas utilizadas:A. Accuracy
Accuracy =TP+TN
TP+TN +FP+FN(3)
Mide la proporcion de predicciones correctas. Esutil en datos
balanceados, pero engañosa en clases desbalanceadas.
B. Precision
Precision =TP
TP+FP(4)
Indica que proporcion de predicciones positivas fueron correc-
tas. Relevante cuando los falsos positivos son costosos.
C. Recall (Sensibilidad)
Recall =TP
TP+FN(5)
Mide la capacidad del modelo para identificar correctamente
los positivos. Importante en contextos donde los falsos nega-
tivos son criticos.
D. F1-Score
F1 =2·Precision ·Recall
Precision +Recall(6)
Es la media armonica entre precision y recall, usada en casos
de desbalance de clases.
V. C ASO DE ESTUDIO
Se evaluo un modelo de deteccion de cancer con 1000
pacientes.
•Clase positiva: 30 pacientes con cancer.
•Clase negativa: 970 pacientes sin cancer.
Matriz de confusion:
Cancer No cancer
Cancer 25 (TP) 20 (FP)
No cancer 5 (FN) 950 (TN)
Resultados:
•Accuracy:25+950
1000= 97.5%
•Recall:25
25+5= 83.3%
•Precision:25
25+20= 55%
•F1-Score:2·0.55·0.833
0.55+0 .833≈66.2%
A pesar del alto valor de accuracy, las metricas muestran
limitaciones en la deteccion de la clase positiva.
VI. METRICAS AVANZADAS
A. Curva ROC
La curva ROC ( Receiver Operating Characteristic ) mues-
tra el desempeño de un clasificador binario para distintos
umbrales. Representa la Tasa de Verdaderos Positivos (TPR)
frente a la Tasa de Falsos Positivos (FPR).

Fig. 2. Ejemplo de curva ROC y calculo de AUC.
B.´Area Bajo la Curva (AUC)
El AUC mide elarea bajo la curva ROC:
•AUC = 0.5: clasificador aleatorio.
•AUC cercano a 1: modelo con gran poder de discrimi-
nacion.
VII. P ROCESAMIENTO DE DATOS
A. Problemas encontrados en la calidad de datos
En escenarios reales, los datos suelen presentar problemas
que afectan directamente la efectividad de los algoritmos de
mineria y aprendizaje automatico. Los principales son:
•Incompletitud: valores faltantes en atributos importantes.
Ejemplo: si un producto estaba en oferta y no se registro
la variable.
•Inexactitud o ruido: errores de medicion, valores
atipicos o entradas anomalas en transacciones.
•Inconsistencia: discrepancias en nombres, codigos
o formatos. Ejemplo: fechas almacenadas como
DD/MM/AAAA en una base de datos y como
MM-DD-YYYY en otra.
Un caso ilustrativo es la recoleccion de datos medicos: en la
medicion de presion sanguinea, un valor faltante no implica
que el registro deba eliminarse, ya que otras caracteristicas
(edad, peso, historial clinico) si aportan informacion valiosa.
Esto demuestra que los datasets requieren preprocesamiento
antes de aplicar tecnicas de mineria o aprendizaje.
B. Causas de datos defectuosos
•Instrumentos de recoleccion defectuosos.
•Errores humanos o computacionales en la entrada de
datos.
•Valores falsos en campos obligatorios (ejemplo: fecha por
defecto “1 de enero” para ocultar cumpleaños), conocidos
como datos faltantes disfrazados .•Inconsistencias en convenciones de nombres, codigos o
formatos.
•Registros duplicados que requieren procesos de data
cleaning .
C. Causas de incompletitud
•Atributos de interes no siempre disponibles o considera-
dos irrelevantes en el momento de captura.
•Fallos tecnicos o malentendidos durante la recoleccion.
•Eliminacion de registros por inconsistencias.
•Ausencia de historial o modificaciones no registradas.
•Valores faltantes en atributos clave que deben ser inferi-
dos.
D. Causas de inconsistencias
•Diferencias en convenciones de nombres o codigos.
•Formatos de entrada distintos para un mismo atributo.
•Conflictos entre bases de datos heterogeneas.
•Errores en la integracion de fuentes multiples.
•Actualizaciones parciales que dejan registros contradic-
torios.
E. Principales tareas en el preprocesamiento
•Data cleaning: eliminacion de ruido, correccion de in-
consistencias y tratamiento de valores faltantes.
•Data integration: combinacion de datos provenientes de
multiples fuentes heterogeneas en un repositorio unifi-
cado.
•Data reduction: reduccion de volumen mediante se-
leccion de atributos, reduccion de dimensionalidad o
discretizacion.
•Data transformation: normalizacion, estandarizacion,
agregacion y construccion de nuevas variables.
•Data discretization: transformacion de atributos contin-
uos en categorias o intervalos.
F . Data Cleaning: Tratamiento de valores faltantes y ruido
1) Valores faltantes:
•Ignorar tuplas con valores faltantes (riesgoso si se pierde
mucha informacion).
•Completar manualmente (costoso en grandes datasets).
•Usar un valor global constante (ej. “desconocido”).
•Rellenar con la media, mediana o moda, tambien por
clase.
•Inferir valores mediante modelos estadisticos o de ML
(regresion,k-NN, ´arboles de decision).
2) Binning: Binning agrupa valores en intervalos ( bins) y
reemplaza cada valor por:
•La media del bin.
•La mediana del bin.
•El borde mas cercano del bin.
Ejemplo: salarios ruidosos [2950, 3000, 3020, 8000]. El bin
(2900–3100) se reemplaza por la media (2990), mientras que
8000 queda como posible outlier.

3) Suavizado de ruido:
•Ajustar una funcion matematica (lineal o no lineal) para
suavizar fluctuaciones. Ejemplo: regresion lineal en ven-
tas mensuales.
•Aplicar tecnicas de filtrado como la media movil:
MA 7(t) =1
76X
i=0xt−i
donde xtes el valor en el diat. Esto genera una curva
suavizada que refleja la tendencia real.
G. Data Integration: Manejo de redundancia
La misma informacion puede estar registrada varias veces
o con diferencias. Ejemplo: un cliente como “Juan Perez”
en una base de datos y “J. A. Perez” en otra. Se aplican
pruebas estadisticas como la chi-cuadrado (χ2) para detectar
redundancia o asociaciones entre variables categoricas:
H0:P(Ai∩Bj) =P(Ai)P(Bj)
Siχ2
calculado ≤χ2
α,d f, se acepta la hipotesis de independencia.
REFERENCES
[1] A. Burkov, The Hundred-Page Machine Learning Book . Andriy Burkov,
2019. [Online]. Available: https://themlbook.com/