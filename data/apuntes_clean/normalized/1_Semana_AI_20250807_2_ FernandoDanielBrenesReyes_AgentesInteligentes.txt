Inteligencia Artificial
Apuntes de la clase 07/08/2025
Fernando Daniel Brenes Reyes
Escuela de Ingenieria en Computacion
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
2020097446@estudiantec.cr
Abstract —Estos apuntes organizan y amplian el material
introductorio de la clase sobre Inteligencia Artificial . Se incluyen
noticias recientes , fundamentos tecnicos , cuestiones practicas,
una linea de tiempo historica, y una descripcion de las principales
ramas del aprendizaje automatico. El documento esta preparado
en formato IEEE, con lugares marcados para figuras y sugeren-
cias bibliograficas.
Index Terms —Inteligencia Artificial, GPT-5, Autos Autonomos,
Datos, Aprendizaje Supervisado, Aprendizaje No Supervisado.
I. I NTRODUCCION
La Inteligencia Artificial (IA) es un campo multidisci-
plinario que combina informatica, estadistica, matematica
y aspectos del dominio de aplicacion para crear sistemas
que pueden percibir, razonar, aprender y actuar. En esta
compilacion ampliada se cubren conceptos teoricos, avances
recientes y aplicaciones practicas relevantes para un curso
introductorio.
II. N OTICIAS Y CONTEXTO RECIENTE
A. GPT-5 y modelos de lenguaje avanzados
A mediados de 2025 emergieron nuevas generaciones de
grandes modelos de lenguaje con capacidades multimodales,
mejor manejo del contexto y mejoras en razonamiento. Estos
modelos impactan fuertemente en herramientas de productivi-
dad (resumenes, generacion de codigo, asistencia de escritura)
y han generado debate acerca de su adopcion responsable y
efectos laborales.
Fig. 1. Linea simplificada de evolucion de modelos de lenguaje: GPT-1 →
GPT-2→GPT-3→GPT-4B. Impacto en el empleo y en programadores
La automatizacion con IA esta permitiendo a organizaciones
reducir tiempo en tareas repetitivas (redaccion de correos,
generacion de reportes, tests basicos de software). Para pro-
gramadores esto significa:
•Aumento de productividad: asistentes que generan es-
queleto de codigo y pruebas unitarias.
•Cambio en habilidades requeridas: mayorenfasis
en diseño, validacion, ´etica, pruebas adversariales y
orquestacion.
•Riesgos: tareas de bajo nivel y rutinas repetitivas pueden
verse desplazadas; se recomienda desarrollar habilidades
de alto valor (arquitectura, ingenieria de datos, DevOps,
ML Ops).
C. Autos autonomos en California
California es uno de los centros donde empresas realizan
pruebas y despliegues de vehiculos autonomos; estos sistemas
integran LIDAR, camaras, mapas HD y planificacion en
tiempo real. Lasareas de interes incluyen:
•Sensores y fusion:LIDAR + camaras + radar + GPS.
•Percepcion: deteccion y clasificacion de peatones,
vehiculos y señales.
•Planificacion:toma de decisiones en entornos urbanos
complejos.
•Protocolos de emergencia: procedimientos para fallas
del sistema, intervencion humana y registro de eventos.
Fig. 2. Vehiculo autonomo: sensores, percepcion, planificacion y control.

III. D EFINICIONES Y CONCEPTOS BASICOS
A. ¿Que es inteligencia?
No existe una definicionunica aceptada. En IA operativa se
suele entender como la capacidad de un sistema para percibir
su entorno, razonar, tomar decisiones autonomas y adaptarse
a cambios . Distintos campos (psicologia, filosofia, ciencias
de la computacion) aportan matices: aprendizaje, simbolismo,
razonamiento probabilistico, entre otros.
B. Autonomo vs. adaptativo
Autonomo: actua sin intervencion humana constante.
Adaptativo: modifica su comportamiento basandose en nueva
informacion o retroalimentacion.
Un sistema puede ser autonomo pero no adaptativo (p. ej. un
robot con una ruta fija) o adaptativo pero no completamente
autonomo (p. ej. un asistente que sugiere cambios que un
humano valida).
C. Capacidad de generalizacion
La generalizacion es la habilidad de un modelo de de-
sempeñarse bien sobre datos no vistos durante el entre-
namiento. Es el objetivo central al medir la utilidad practica
de un modelo.
IV. D EEPLEARNING Y REDES NEURONALES
A. Perceptron y origenes
El perceptron (decada de 1950) es un modelo de unidad
de decision lineal que calcula una combinacion ponderada de
entradas y aplica una funcion de activacion. Funciona bien
para problemas linealmente separables, pero no puede resolver
problemas no lineales (ej. XOR).
B. Redes profundas y arquitecturas comunes
El deep learning usa redes con muchas capas: perceptrones
multicapa (MLP), redes convolucionales (CNN) y redes re-
currentes (RNN/LSTM/Transformer). Cada arquitectura esta
orientada a distintos tipos de datos:
•CNN: imagenes y datos con estructura espacial.
•RNN / LSTM: secuencias temporales y texto
(historicamente).
•Transformers: atencion y modelado de dependencias a
larga distancia (estado del arte en NLU y NLG).
C. Yann LeCun y las CNN
Yann LeCun fue pionero en redes convolucionales (LeNet)
y en su aplicacion al reconocimiento de digitos. Las CNN
aprenden filtros que detectan caracteristicas locales (bordes,
texturas) y luego construyen representaciones de alto nivel
mediante capas sucesivas.
Fig. 3. Esquema de una red convolucional
V. D ATOS :EL CORAZON DE LA IA
A. Calidad y preprocesamiento
Los datos deben ser:
•Representativos del problema real.
•Limpios : sin errores obvios (p. ej. mezcla Cel-
sius/Fahrenheit).
•Balanceados o bien tratados para evitar sesgos.
•Steven Pacheco 2025 - Si tenemos mal los datos, mala
es la salida de nuestra funcion
Tecnicas comunes: normalizacion, imputacion
(media/mediana), deteccion y tratamiento de outliers,
ingenieria de caracteristicas y enriquecimiento.
B. Sesgos y equidad
Los datasets reflejan las desigualdades del mundo real.
Un modelo entrenado con datos sesgados puede perpetuar
discriminaciones. Ejemplos practicos:
•Reconocimiento facial con peor desempeño en ciertos
grupos demograficos.
•Modelos de credito que penalizan poblaciones subrepre-
sentadas.
Buenas practicas: auditorias de sesgo, conjuntos de prueba
estratificados, transparencia en datos y procesos.
C. Ejemplo del profe: Celsius vs Fahrenheit
Un error clasico en datasets es mezclar unidades. Si un
campo de temperatura contiene valores en ambas escalas sin
etiqueta, el modelo puede aprender patrones erroneos. Es
esencial normalizar unidades y validar rangos.
VI. B REVE HISTORIA DE LA IA ( LINEA DEL TIEMPO )
•1950s: Perceptron y primeras investigaciones (Rosen-
blatt).
•1960s: Nacimiento temprano del Machine Learning y
primeros sistemas simbolicos.
•1970s: Lenguajes logicos (Prolog), algoritmos clasicos
(Dijkstra).
•1980s: Inicio de la experimentacion con autos autonomos.
•1990s: Resurgimiento con redes multicapa y aprendizaje
por refuerzo.
•2000s: Auge del reconocimiento facial y vision por
computadora.
•2010s–2020s: Deep learning, grandes modelos de
lenguaje, despliegues comerciales.

VII. R AMAS DEL APRENDIZAJE AUTOMATICO
A. Aprendizaje Supervisado
Consiste en aprender una funcionf:X→Ya partir
de ejemplos etiquetados (xi, yi). Tecnicas: regresion lineal,
SVM, ´arboles, redes neuronales. Se evalua con metricas como
RMSE, accuracy, F1.
B. Aprendizaje No Supervisado
No hay etiquetas; el objetivo es encontrar estructura.
Tecnicas: clustering (k-means, DBSCAN), reduccion de di-
mensionalidad (PCA, t-SNE, UMAP).
C. Aprendizaje por Refuerzo
Agentes aprenden interactuando con un entorno y recibi-
endo recompensas. Aplicaciones: juegos (Atari, Go), control
robotico. Referencia clasica: Sutton & Barto.
Fig. 4. Ejemplo de aprendizaje por refuerzo
VIII. C IENTIFICO VS INGENIERO EN IA
Cientifico de IA: foco en investigacion, nuevos modelos,
experimentos.
Ingeniero de IA / ML Engineer: foco en produccion,
rendimiento, escalabilidad, MLOps y despliegue.
Ambos roles se complementan; en proyectos reales conviven
y colaboran.
IX. T IPOS DE APRENDIZAJE EN IA
A. Aprendizaje Supervisado
•Definicion: Modelo que aprende a partir de datos etique-
tados (caracteristicas + valores conocidos).
•Ejemplo : Predecir el precio de una casa usando sus
caracteristicas.
•Proceso :
–Division: Muestra (caracteristicas) + Etiqueta (valor
objetivo).
–Aproximacion: Minimiza el error mediante una
funcion de perdida (L) .
•Tecnicas :
–Regresion (valores continuos).
–Clasificacion (categorias discretas).B. Aprendizaje No Supervisado
•Definicion: Modelo identifica patrones en datos sin eti-
quetas .
•Ejemplo : Agrupamiento de clientes por habitos de com-
pra.
•Tecnicas :
–Clustering (ej. K-means).
–Reduccion de dimensionalidad (ej. PCA).
C. Comparacion
Aspecto Supervisado No Supervisado
Datos Etiquetados Sin etiquetas
Objetivo Prediccion Descubrir patrones
Ejemplos Regresion, Clasificacion Clustering
Fig. 5. Ejemplo de aprendizaje por refuerzo
CONCLUSION
La IA es un campo en rapida evolucion: combina teoria
matematica, ingenieria de software y consideracioneseticas.
Comprender fundamentos, cuidar la calidad de los datos y
adquirir habilidades practicas (Keras, MLOps, validacion) son
claves para trabajar efectivamente en esteambito.