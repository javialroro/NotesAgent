Apuntes Inteligencia Artificial, Clase 02 de Octubre
Javier Alonso Rojas Rojas
Escuela de Ingenieria en Computacion
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
javrojas@estudiantec.cr
Abstract —Estos apuntes reflejan lo conversado en la clase
del 02 de octubre donde se mencionaron temas como. El fun-
cionamiento de los agentes basados en modelos de lenguaje de
gran escala (LLM) y su papel en la inteligencia artificial moderna.
Se mencionaron las principales herramientas y frameworks para
la creacion de agentes, junto con las diferencias entre sistemas de
un solo agente y multiagente. Ademas, se examina el caso de Sora
de OpenAI como ejemplo de modelo multimodal de generacion
de video y audio, considerando tambien los retoseticos asociados.
Finalmente, se incluye un repaso de los fundamentos de las
redes neuronales, sus funciones de activacion y el proceso de
entrenamiento mediante backpropagation, como base conceptual
de los LLM actuales.
I. I NTRODUCTION
La inteligencia artificial (IA) ha avanzado rapidamente
gracias a los modelos de lenguaje de gran escala (LLMs) y al
desarrollo de agentes inteligentes capaces de actuar y razonar
en distintos contextos. Estos sistemas han transformado la
generacion de texto en un proceso de planificacion y ejecucion
mas complejo, permitiendo la creacion de agentes autonomos
que integran herramientas y colaboran entre si.
Los apuntes abordan los fundamentos y la arquitectura de
los agentes basados en LLM, distinguiendo entre sistemas
individuales y multiagente, y destacando el papel del Chain of
Thought (CoT) como mecanismo clave para el razonamiento
estructurado. Ademas, se incluye el caso de estudio Sora de
OpenAI y un repaso de las bases neuronales del aprendizaje
profundo, como las funciones de activacion y el entrenamiento
porbackpropagation .
II. M ENCION DE LECTURA DE AGENTES
Se hizo un repaso general de la lectura “From Language to
Action: A Review of Large Language Models as Autonomous
Agents and Tool Users”. Explico que lo fundamental para
el proximo quiz del martes es comprender lo esencial: los
modelos de lenguaje (LLMs) han pasado de ser simples
generadores de texto a actuar como agentes autonomos con
capacidad para razonar, planificar, usar memoria e interactuar
con herramientas externas. La lectura tambien distingue entre
sistemas de un solo agente y sistemas multiagente, en los
que varios modelos cooperan para resolver tareas mas com-
plejas. Ademas, se analizan sus aplicaciones enareas como
la investigacion, la programacion, la salud, la robotica y las
simulaciones, junto con los principales desafios que enfrentan:
la memoria limitada, la seguridad, laetica y la necesidad de
mejores metodos de evaluacion.
Fig. 1. Sora 2
III. S ORA 2BYOPENAI
Sora 2 es la nueva version del modelo multimodal de
OpenAI, capaz de generar video y audio sincronizados a
partir de texto. Presenta notables mejoras en realismo fisico,
coherencia visual y control creativo. Su funcion de cameos
permite insertar la imagen y voz del usuario, bajo consen-
timiento, ampliando las posibilidades narrativas y expresivas.
Ademas, han desarrollado un tipo de red social donde se
pueden compartir los videos creados con el modelo.
El modelo ofrece mayor precision en iluminacion,
movimiento y sonido, ademas de opciones de control estilistico
mediante steerability . OpenAI ha incorporado medidaseticas
para evitar la reproduccion de personas reales o la generacion
de contenido sensible, lanzandolo de forma gradual mediante
laSora app y futuras APIs. Sora 2 representa un avance sig-
nificativo en la generacion audiovisual con IA, aunque plantea
retos importantes en materia de privacidad y autenticidad
digital.
IV. R EPASO DE REDES NEURONALES
A. El Perceptron y su evolucion
El perceptron puede entenderse de forma similar a una
regresion logistica, aunque se diferencia en la funcion de
perdida que utiliza. Durante la historia de la inteligencia
artificial surgio el llamado “invierno de la IA” , en parte debido
al problema del XOR, ya que este no podia ser representado
adecuadamente por un modelo lineal ni por un perceptron
simple.

Fig. 2. Funciones de activacion
B. El problema del XOR
El principal inconveniente del perceptron simple es que el
problema XOR no es linealmente separable, por lo que este
modelo no puede ofrecer una solucion adecuada. Esto dio
origen a las redes neuronales multicapa (MLP), capaces de
resolver problemas no lineales y ampliar significativamente el
rango de aplicaciones posibles.
C. Inspiracion biologica
Las redes neuronales artificiales se inspiran en el fun-
cionamiento del cerebro humano. Cada neurona recibe señales
a traves de sus dendritas (entradas), las procesa en el nucleo
mediante una combinacion lineal, y decide si transmite o no
la señal segun una funcion de activacion.
D. Funciones de activacion
Las funciones de activacion introducen no linealidad en el
modelo, permitiendo que la red aprenda relaciones complejas:
•ReLU: g(x) = max(0 , x); eficiente, pero puede generar
“neuronas muertas” cuando el gradiente es cero.
•Leaky ReLU: introduce una pequeña pendiente en la
parte negativa para evitar neuronas inactivas.
•Tanh: produce salidas en el rango (−1,1),´util para
manejar valores positivos y negativos.
•Sigmoide: transforma la entrada en valores entre 0 y 1,
comun en tareas de clasificacion binaria.
E. Perceptron Multicapa (MLP)
ElMultilayer Perceptron (MLP) extiende el perceptron sim-
ple añadiendo capas ocultas que permiten resolver problemas
no lineales. Su estructura general incluye:
•Capa de entrada: recibe los datos originales Xi.
•Capas ocultas: realizan transformaciones y calculos in-
ternos.
•Capa de salida: entrega el resultado final, cuyo tamaño
depende del tipo de problema.
El entrenamiento se realiza mediante backpropagation , que
calcula el error del modelo y ajusta los pesos utilizando
descenso de gradiente.
Fig. 3. Comportamiento Jerarquico
Fig. 4. Funcionamiento de las CNN
Cada capa se calcula de la siguiente forma:
h(0)=σ(XW 0+b0) (1)
h(1)=σ(h(0)W1+b1) (2)
h(n)=g(h(n−1)Wn+bn) (3)
F . Capas de salida y distribucion
Las salidas pueden ser categoricas o continuas:
•En clasificacion, se usa softmax como funcion de salida.
•En regresion, se emplea una funcion lineal.
En todos los casos, la activacion final g(x)debe ser no lineal
para permitir un aprendizaje mas expresivo.
G. Maldicion de la dimensionalidad
Cuando se trabaja con datos de muchas variables, los puntos
se dispersan en un espacio de alta dimension, reduciendo su
densidad y dificultando el hallazgo de patrones significativos.
H. Comportamiento jerarquico
Como vemos en la Figura 3, las redes neuronales apren-
den de forma jerarquica, combinando funciones simples para
formar otras mas complejas. Esto permite construir representa-
ciones compactas y eficientes, en las que un numero reducido
de pesos puede modelar funciones avanzadas.
I. CNN
En las redes convolucionales (CNN), las primeras capas
detectan bordes o patrones basicos, las intermedias aprenden
estructuras mas definidas y lasultimas capas reconocen objetos
completos, como rostros o figuras, esto representado en la
Figura 4.
J. Representaciones vectoriales
En el procesamiento de lenguaje natural (NLP), las palabras
se representan como vectores en un espacio de alta dimension,
de modo que las palabras con significados o funciones simi-
lares se ubican proximas entre si en dicho espacio.

Fig. 5. Tangente hiperbolica
V. F UNCIONES DE ACTIVACION
Las funciones de activacion son un componente esencial
en las redes neuronales, ya que permiten introducir la no
linealidad necesaria para modelar relaciones complejas entre
los datos. A continuacion, se describen las funciones mas rel-
evantes junto con sus principales caracteristicas matematicas.
A. Lineal
La funcion lineal se define como:
f(x) =ax
Su derivada es constante ( f′(x) =a), por lo que el modelo
no puede aprovechar el descenso del gradiente para aprender
patrones complejos. Debido a su caracter estrictamente lineal,
no introduce capacidad de generalizacion ni no linealidad en
la red.
B. Sigmoide
La funcion sigmoide produce salidas entre 0 y 1, es siempre
positiva, acotada y estrictamente creciente:
σ(x) =1
1 +e−x
A pesar de su utilidad inicial, presenta el problema del
vanishing gradient : la derivada tiende a cero en los extremos
de la funcion, lo que hace que el aprendizaje sea lento o
incluso se detenga en redes profundas.
C. Tangente Hiperbolica (Tanh)
La funcion tangente hiperbolica tiene un rango de salida
entre (−1,1)como vemos en la Figura 5 y su forma es similar
a la sigmoide, pero centrada en el origen:
tanh( x) =ex−e−x
ex+e−x
Esto permite representar tanto valores positivos como nega-
tivos, lo que facilita la convergencia del modelo. Sin embargo,
al igual que la sigmoide, tambien sufre del problema del
gradiente desvanecido en los extremos.D. Parametric ReLU (PReLU)
La funcionParametric ReLU (PReLU) es una variante
de la funcion ReLU tradicional, como se muestra en la
figura ??. A diferencia de la ReLU estandar, esta introduce
un parametro αque se aprende durante el entrenamiento y
controla la pendiente en la region negativa. De esta manera,
el modelo puede ajustar automaticamente el grado de “fuga”
en los valores menores que cero, evitando el problema de las
neuronas muertas .
Su definicion matematica es la siguiente:
g(x) =(
αx, six <0
x, six≥0
La derivada correspondiente es:
dg(x)
dx=(
α, six <0
1,six≥0
El parametro αse entrena junto con el resto de los pesos de
la red, lo que otorga al modelo mayor flexibilidad y capacidad
de adaptacion frente a distintas distribuciones de datos. Por
esta razon, la PReLU suele ofrecer un mejor desempeño en
arquitecturas profundas donde la ReLU estandar podria perder
gradiente.
E. Softmax
La funcion Softmax transforma las salidas de la capa final
en una distribucion de probabilidad, como vemos en la figura
6. Su expresion se define como:
σ(x)j=exj
PK
k=1exk
donde cada valor xjse denomina logit. Esta funcion se utiliza
principalmente en problemas de clasificacion multiclase, ya
que garantiza que todas las salidas sean positivas y sumen 1.
•El uso de exasegura una funcion estrictamente creciente
y evita valores negativos.
•Se emplea junto con la funcion de perdida Cross-
Entropy Loss , tambien llamada Log-Loss .
La perdida se define como:
L=−logP(Y=yi|X=xi)
y, en el caso multiclase:
L=−logesk
PC
j=1esj
F . Seleccion de la funcion de activacion
La eleccion de la funcion de activacion depende del tipo de
problema y la arquitectura de la red. Las funciones Sigmoid y
Tanh tienden a sufrir el problema del gradiente desvanecido,
por lo que no son recomendadas para redes profundas. En
la practica, se suele comenzar con la funcionReLU por
su eficiencia computacional y buen rendimiento en modelos
deDeep Learning . Si esta presenta problemas (por ejemplo,
neuronas muertas), se pueden utilizar variantes como Leaky
ReLU oParametric ReLU , que permiten mantener un flujo
de gradiente estable incluso en valores negativos.

Fig. 6. Uso de Softmax
Fig. 7. Forward Propagation y Back Propagation
VI. B ACKPROPAGATION
El algoritmo de backpropagation permite calcular cuanto
contribuye cada peso al error final de la red, actualizando los
parametros en la direccion opuesta a la propagacion hacia
adelante. Este proceso es esencial para que la red neuronal
aprenda y mejore su desempeño durante el entrenamiento. Esto
representado en la figura 7.
A. Forward Propagation
Consiste en calcular la salida de la red, enviando los datos
desde la capa de entrada hacia las capas ocultas hasta obtener
la salida final.
B. Backpropagation
implica propagar el error desde la capa de salida hacia las
capas anteriores, calculando las derivadas parciales respecto a
los pesos y sesgos para ajustar los parametros del modelo.
C. Optimizacion del grafo computacional
Consideremos una red neuronal como la de la figura 8,
donde cada capa contiene unaunica neurona y la funcion de
activacion utilizada es la sigmoide. El calculo se puede dividir
en las siguientes partes:
•Funcion de perdida (MSE):
Li= (a(L)−yi)2
donde a(L)es la salida de la red y yiel valor esperado.
•Entrada:
z(L)=w(L)a(L−1)+b(L)
•Salida:
a(L)=g(z(L))
Fig. 8. Red neuronal simple
Fig. 9. Red neuronal mas compleja
donde grepresenta la funcion de activacion.
Los parametros w(L)yb(L)se actualizan utilizando la regla
de la cadena, derivando el error con respecto a cada parametro
y aprovechando la salida de la capa anterior.
D. Vector gradiente
Elvector gradiente esta formado por todas las derivadas
parciales de los parametros (pesos y sesgos) de la red. Durante
el calculo del gradiente se identifican operaciones repetidas,
lo que permite optimizar los calculos en el algoritmo de back-
propagation mediante reutilizacion de resultados intermedios
(cache).
E. Redes con multiples neuronas
En redes con mayor dimensionalidad como la de la figura
9, se introducen notaciones adicionales:
•Superindice: indica la capa. Ejemplo: a(l)representa la
activacion en la capa l.
•Subindice: indica la neurona dentro de una capa. Ejem-
plo:a(l)
jes la j-´esima neurona en la capa l.
•Pesos: se representan como w(l)
j,k, que conecta la neurona
a(l−1)
kcona(l)
j, aca j seria el destino y k el origen.
Cada neurona de la capa lrecibe entradas desde todas las
neuronas de la capa anterior (l−1), siguiendo los pasos:
•Preactivacion:
z(l)
j=b(l)
j+nl−1X
k=1w(l)
j,ka(l−1)
k
•Activacion:
a(l)
j=g(z(l)
j)
Para obtener la activacion de una neurona destino, se
calculan las contribuciones de todas las neuronas de la capa
anterior, multiplicando los pesos de conexion correspondientes
por la activacion de cada neurona origen. Posteriormente, se

suman estos productos junto con el sesgo asociado, repitiendo
el proceso para cada neurona de la capa.
F . Funcion de perdida global
La funcion de perdida global se obtiene sumando las difer-
encias entre la salida de cada neurona en la capa de activacion
ly su valor esperado yj:
Li=nlX
j=1(a(l)
j−yj)2
G. Aplicacion de la regla de la cadena
Dado que las funciones Li,z(l)
jya(l)
jestan encadenadas, es
necesario aplicar la regla de la cadena para derivar cada peso
w(l)
j,ky sesgo b(l)
j. Solo la derivada∂z(l)
j
∂w(l)
j,kcambia con cada peso
actualizado, mientras que las demas se mantienen constantes
dentro de la capa.
Las derivadas parciales relevantes son:
∂Li
∂a(l)
j= 2(a(l)
j−yj)
∂a(l)
j
∂z(l)
j=g(z(l)
j)(1−g(z(l)
j))
∂z(l)
j
∂w(l)
j,k=a(l−1)
k
A partir de estas derivadas, los pesos y sesgos se actualizan
siguiendo el descenso del gradiente:
w(l)
j,k←w(l)
j,k−η∂Li
∂w(l)
j,k, b(l)
j←b(l)
j−η∂Li
∂b(l)
j
donde ηrepresenta la tasa de aprendizaje.
En redes mas profundas, al extender el calculo hacia capas
anteriores (l−1), el numero de parametros y combinaciones
a derivar aumenta considerablemente, incrementando la com-
plejidad computacional del algoritmo.