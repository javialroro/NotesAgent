Apuntes de Semana 5, Clase #2
Mauricio Campos Cerdas
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
maucampos@estudiantec.cr
Abstract —This document presents class notes on handling
outliers, the concepts of bias and variance, and an introduction
to logistic regression as a classification algorithm. Techniques for
identifying and addressing outlying values are discussed, along
with methods for splitting datasets and common scenarios en-
countered during training and validation. As well as the sigmoid
function and parameter optimization in logistic regression are
introduced, including the derivation of the sigmoid function.
Index Terms —Outliers, bias, variance, logistic regression, clas-
sification, sigmoid function, parameter optimization, training and
validation, Overfitting, Underfitting
I. N OTICIAS DE LA SEMANA
A. Evento IEEE
IEEE esta organizando un evento donde se tocaran temas
muy interesantes, incluyendo la inteligencia artificial. Vendran
personas de gran renombre a dar charlas, habra comida y
demas. Se pide registrarse para calcular la alimentacion para
el dia del evento.
B. Problema con las referencias y la IA
Se esta produciendo un fenomeno en el que cada vez mas
articulos, notas y sitios web son generados con inteligencia
artificial y se referencian entre si. Esto puede llevar a que
la propia IA se cite a si misma, provocando un aumento de
referencias generadas artificialmente.
C. Modelo Nano Banana
Google lanzo un nuevo modelo llamado Nano Banana. Su
atractivo se encuentra que a diferencia de otros modelos, este
agarra la imagen que esta como input y la modifica sin tener
que generarla otra vez. Se dio un ejemplo de un experimento
donde una IA tenia que modificar una foto varias veces y se
llego a evidenciar que hubo un sesgo de generar la imagen de
la persona cada vez con rasgos mas latinos.
II. P OTENCIALES PROBLEMAS DE LA REGRESIONLINEAL
•No linealidad: En regresion lineal se asume que ex-
iste una relacion lineal entre las variables predictoras
y la variable respuesta. Sin embargo, esto no siempre
se cumple, lo que provoca que el modelo no capture
adecuadamente la relacion y que los residuos presenten
patrones sistematicos (por ejemplo, con forma parabolica)
en lugar de distribuirse aleatoriamente (ver Fig. 1).
Una estrategia para enfrentar este problema es aplicar
feature engineering . Un ejemplo es incorporar terminos
polinomicos adicionales a las variables, lo que permite
aproximar mejor relaciones no lineales.
Fig. 1. Residual plots
•Datos sobresalientes: Siempre existiran outliers, ya sea
por ruido o error humano. Lo que pasa es que nos afecta
a nuestro modelo, siempre habra cierta sensibilidad hay
que tratarlos para evitar que nos afecte en gran medida
nuestro modelo.
A. Metodos para tratar outliers
– Standardized Residuals: Tenemos el calculo de
los residuos y calculamos la desviacion estandar,
para asegurarnos de que nuestros datos siguen una
distribucion normal. A partir de que los tenemos
estandarizados, calculamos a cuantas desviaciones
estandar se encuentra ese dato. Lo que nos dira
es el limite de hasta donde se consideran datos
sobresalientes.
∗ |z|>2: posible outlier.
∗ |z|>3: outlier muy probable, se recomienda
excluir.
– Regla del rango intercuartilico (IQR): Definido
como IQR =Q3−Q1. Los datos que se encuentran
fuera del intervalo [Q1−1.5·IQR, Q 3 + 1.5·IQR]
se consideran outliers.
– Winsorizacion:Tecnica que consiste en reemplazar
los valores extremos por los percentiles limite (por
ejemplo, 5% y 95%).
III. S ESGO Y VARIANZA
El dataset suele dividirse en train y test (80/20)
A. Training set
Se utiliza para ajustar el modelo. Nos puede pasar que
entrenemos el modelo mucho tiempo, lleguemos al final y

Fig. 2. Underfitting, Ideal, Overfitting plots
nos damos cuenta de que fallamos el examen. Si dedicamos
mucho al entrenamiento pero nada a generalizar, se llama
overfitting. Por eso queremos hacer tests pequeños durante el
entrenamiento, con el validation set.
B. Validation set
Nos dice si los hiperparametros son adecuados o no, para
no continuar si no lo son y asi no desperdiciar recursos.
C. Tecnicas de subdividir el dataset
•Random Sampling: Se usa siempre que tengamos clases
balanceadas. Si los datos no estan balanceados, pueden
quedar mal distribuidos, con mas datos de una clase que
de la otra.
•Stratified Sampling: Usado para datos imbalanceados,
asegura una representacion de todas las clases por sepa-
rado.
•K-Fold Cross-Validation: Division en kpartes, en cada
iteracion se usan k−1para entrenamiento y 1 para
validacion.
D. Escenarios posibles
•Escenario ideal: El modelo presenta bajo error tanto en
training como en testing. Puede evitar el ruido de los
datos y generalizar correctamente. Por cadaepoca de
entrenamiento el error deberia ir disminuyendo, tendiendo
siempre a la baja.
•Overfitting: Ocurre cuando el error en el validation set
empieza a crecer o se estanca. Esto indica que el modelo
era bueno hasta ciertaepoca de entrenamiento, pero luego
empieza a sobreajustarse a los datos de entrenamiento,
produciendo overfitting. A esta tecnica de detener el
entrenamiento antes de que esto suceda se le llama early
stopping.
•Underfitting: Se da cuando el error es alto tanto en
training como en testing. Esto se conoce como under-
fitting, que ocurre cuando el modelo no logra ajustarse
correctamente a los datos. Es lo opuesto al overfitting y
se caracteriza por un alto sesgo. Para ver graficamente
estos escenarios, ver Fig. 2).
•Bias-Variance Tradeoff: Validacion con buen resultado,
pero entrenamiento con alto error. Es raro que suceda y
tal vez hay errores de calculo.
Fig. 3. Linear vs Logistic Regression
E. Alto Bias
Cuando el modelo comete muchos errores en el training
set, se produce underfitting. Esto ocurre porque el modelo
asume demasiado del training set, no utiliza todas los features
disponibles y es demasiado simple para capturar la compleji-
dad de los datos. Para evitar un alto sesgo, se puede utilizar
un modelo mas complejo. Ademas, es importante revisar que
los features del training set sean adecuadas para la naturaleza
del problema, ya que si no tienen la capacidad de capturar la
informacion relevante, el modelo no podra hacer predicciones
correctas.
F . Alta Varianza
Ocurre cuando el modelo se ajusta demasiado a los datos
de entrenamiento y no es capaz de generalizar correctamente.
Esto suele suceder cuando los datos son de alta dimension-
alidad y hay pocos ejemplos disponibles. Para evitar la alta
varianza, se pueden usar modelos mas simples, reducir la
dimensionalidad de los datos, obtener mas ejemplos y aplicar
tecnicas de regularizacion.
IV. R EGRESIONLOGISTICA
Aunque su nombre contenga la palabra regresion, en re-
alidad la regresion logistica es un algoritmo de clasificacion
binaria. Distingue entre dos clases ( 0y1), estimando proba-
bilidades. Fig. 3).
A. Distribucion de Bernoulli
Utilizamos una distribucion de Bernoulli para la ocurrencia
de un evento binario.
P(Y=k) =pk(1−p)1−k, k∈ {0,1}
B. Funcion Sigmoide
Es una funcion que no se comporta linealmente. Tiene un
Codominio de [0, 1]
σ(x) =1
1 +e−x
Nota: x puede ser cualquier numero, hasta el resultado de otra
funcion. Ver Fig. 4).

Fig. 4. Sigmoid plot
C. Clasificador
•Siy <0.5, se clasifica como 0.
•Siy≥0.5, se clasifica como 1.
El umbral puede ajustarse segun el problema.
D. Modelo combinado
Al aplicar la sigmoide a una funcion lineal fw,b(x) =wx+
b, obtenemos:
fw,b(x) =1
1 +e−(wx+b)
La relacion de los features y pesos se da por regresion lineal.
Lo que nos da es la probabilidad de que un evento suceda.
E. Optimizacion
En la regresion logistica necesitamos optimizar los pesos
wy el sesgo b. Para actualizar estos pesos, es necesario
contar con una funcion de perdida Lque sea adecuada para
probabilidades, ya que el MSE ya no es lo apropiado en este
caso.
F . Derivada de la sigmoide
σ(x) =1
1 +e−x
Usando la regla del cociente:
σ′(x) =1′·(1 +e−x)−(1·(1 +e−x)′)
(1 +e−x)2
σ′(x) =0−1·(1′+ (e−x)′)
(1 +e−x)2
σ′(x) =−(0−(e−x))
(1 +e−x)2
σ′(x) =e−x
(1 +e−x)2σ′(x) =e−x+ 1−1
(1 +e−x)2
σ′(x) =e−x+ 1
(1 +e−x)2−1
(1 +e−x)2
De la fraccion izquierda, puedo cancelar
σ′(x) =1
(1 +e−x)−1
(1 +e−x)2
Aplicamos factor comun
σ′(x) =1
(1 +e−x)·(1−1
(1 +e−x))
Como1
(1+e−x)=σ(x), decimos que:
σ′(x) =σ(x) 
1−σ(x)
REFERENCES
[1] Amazon Web Services, “Model Fit: Underfitting vs. Overfit-
ting,”. Available: https://docs.aws.amazon.com/machine-learning/latest/
dg/model-fit-underfitting-vs-overfitting.html.
[2] University of Virginia Library, “Understanding Diagnostic Plots for
Linear Regression Analysis,”. Available: https://library.virginia.edu/data/
articles/diagnostic-plots.
[3] ML4A, “Neural networks,”. Available: https://ml4a.github.io/ml4a/es/
neural networks/.