Inteligencia Artificial
Apuntes Semana 5, Clase #2
Luis Fernando Benavides Villegas
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
lubenavides@estudiantec.cr
Abstract —Este documento recopila los apuntes de la clase del
jueves 04 de septiembre de 2025 para el curso de Inteligencia
Artificial. Se repasan conceptos clave de regresion lineal y sus
limitaciones, asi como los problemas de overfitting yunderfitting .
Tambien se describen tecnicas de subdivision de datasets y
estrategias para mejorar la capacidad de generalizacion de los
modelos. Finalmente, se introduce la regresion logistica como un
modelo de clasificacion binaria, explicando la funcion sigmoide,
su derivada y el proceso de optimizacion de parametros mediante
descenso del gradiente.
Index Terms —Inteligencia Artificial, regresion lineal, regresion
logistica, funcion sigmoide, overfitting, underfitting, optimizacion
I. N OTICIAS DE LA SEMANA
A. IngenIEEEria Costa Rica
Un evento de Ingenieria que organiza IEEE Costa Rica.
Habra charlas de profesores distinguidos en diversasareas y
participacion de empresas. [1]
B. Referencias falsas en IA
Las “alucinaciones” en inteligencia artificial son cuando los
modelos generan referencias aparentemente validas pero que
en realidad no existen. Esto fue debatido en el grupo Parma
del TEC y se resalto la importancia de siempre verificar las
fuentes. La responsabilidad recae en el usuario de confirmar
la veracidad de la informacion antes de tomarla como cierta.
C. Google Nano Banana
El nuevo modelo de Google enfocado en la edicion de
imagenes que se llama Nano Banana . A diferencia de otros
generadores que recrean la imagen completa desde cero, este
modelo conserva mejor los detalles originales y el contexto.
Asi, al editar una foto mantiene la coherencia entre iteraciones.
Se hablo tambien de posibles sesgos en los modelos, al notar
que repeticiones en imagenes de personas modificaban rasgos
hacia un perfil mas latino.
II. R EPASO DE LA CLASE ANTERIOR
A. Potenciales problemas al aplicar una Regresion Lineal
1) No linealidad: Un supuesto de la regresion lineal es
que la relacion entre las variables predictoras y la variable re-
spuesta es lineal. Cuando no se cumple, los residuos muestranpatrones sistematicos (por ejemplo, en forma de parabola) en
lugar de distribuirse de manera aleatoria. Esto indica que el
modelo lineal no es adecuado. Para resolverlo, una opcion es
aplicar feature engineering , agregando terminos polinomicos
que transformen las variables originales y permitan que la
relacion se aproxime mejor a una forma lineal. De esta manera,
aunque la relacion real sea curva, el modelo puede ajustarse
con menor error.
2) Datos sobresalientes: Surgen por ruido, errores de
medicion o datos atipicos y pueden afectar el ajuste del
modelo. Una forma de tratarlos es estandarizar los residuos
dividiendo entre la desviacion estandar. Una vez normalizados,
se mide cuantas desviaciones estandar se aleja cada dato. Si
un dato esta muy lejos (mas de 2 o 3 desviaciones estandar),
se considera sobresaliente. Otras tecnicas que vimos fueron el
rango intercuartilico, que es el que se usa en graficos de caja
y bigotes, y la Winsorizacion, donde en vez de eliminar datos
atipicos se reemplazan por valores en percentiles limite.
3) Colinealidad: Se da cuando dos o mas predictores estan
altamente correlacionados entre si. Esto hace dificil separar
el efecto de cada variable en la prediccion, afectando la
estabilidad de los coeficientes del modelo. En consecuencia,
los parametros estimados se vuelven poco confiables y muy
sensibles a cambios en los datos. Para detectarla, se pueden
usar medidas como el VIF (Variance Inflation Factor) . Una
solucion comun es eliminar variables redundantes o aplicar
tecnicas de regularizacion.
B. Dataset
Es el conjunto completo de datos disponibles para entrenar
y evaluar un modelo. Normalmente se subdivide en diferentes
partes para poder medir la capacidad de generalizacion y evitar
problemas como el overfitting .
C. Training Set
Subconjunto usado para entrenar el modelo y ajustar sus
parametros. Es donde el algoritmo aprende los patrones pre-
sentes en los datos.
D. Validation Set
Subconjunto usado durante el entrenamiento para evaluar
el rendimiento intermedio del modelo. Sirve para medir si

lo aprendido se generaliza a datos no vistos y para ajustar
hiperparametros. Permite detectar problemas de sobreajuste de
manera temprana sin necesidad de esperar a la prueba final.
E. Tecnicas para subdividir el dataset
1) Random Sampling: Consiste en dividir aleatoriamente
los datos entre entrenamiento y prueba. Es adecuado cuando
las clases estan balanceadas, ya que garantiza representatividad
sin introducir sesgos. El problema surge si las clases estan
desbalanceadas, porque puede que un subconjunto quede con
muy pocos o incluso sin ejemplos de alguna clase.
2) Stratified Sampling: Se usa cuando las clases estan
desbalanceadas. Mantiene la misma proporcion de clases en
los conjuntos de entrenamiento y prueba. De esta forma, si en
el dataset original una clase representa el 90% y otra el 10%,
esa relacion se conserva en las divisiones.
3) K-Fold Cross-Validation: El conjunto de entrenamiento
se divide en Kpartes (folds). En cada iteracion se usa
K−1folds para entrenar y el fold restante para validar. El
proceso se repite Kveces, rotando el fold de validacion. Esto
permite aprovechar mejor los datos disponibles y obtener una
evaluacion mas robusta del modelo.
F . Posibles escenarios de comportamiento de training y vali-
dation
1) Overfitting: El error en training es bajo pero el error
en validation comienza a aumentar despues de cierto punto.
El modelo memoriza los datos de entrenamiento en lugar de
aprender patrones generales. Se captura tambien el ruido de los
datos, lo que provoca que no pueda generalizar. Se caracteriza
por tener alta varianza .
Fig. 1. Ej. de overfitting
 Fig. 2. Ej. de regresion de overfitting
Una tecnica para evitarlo es el early stopping , que consiste
en detener el entrenamiento en laepoca donde el error de
validacion empieza a empeorar.
2) Underfitting: Tanto el error en training como en val-
idation son altos. El modelo no logra aprender patrones de
los datos porque es demasiado simple o incorrecto para el
problema. Se caracteriza por alto sesgo , es decir, asume una
forma equivocada de los datos (por ejemplo, usar un modelo
lineal para datos con comportamiento cuadratico).
Fig. 3. Ej. de underfitting
Fig. 4. Ej. de regresion de underfit-
ting
3) Caso ideal: El error en training es bajo y tambien lo
es en validation. El modelo logra ajustarse a los datos sin
sobreajustarse al ruido y puede generalizar bien a ejemplos no
vistos. Representa un buen equilibrio entre sesgo y varianza.
Fig. 5. Ej. del caso ideal
 Fig. 6. Ej. de regresion del caso ideal
4) Bias-Variance Tradeoff: Es un caso super raro porque
el error en training es alto pero el error en validation es bajo.
Si sucede, puede deberse a errores de calculo o valores mal
tomados, no a un aprendizaje real del modelo.
III. A LTOBIAS
Se presenta cuando el modelo es demasiado simple y
no logra capturar el patron real de los datos, provocando
underfitting . Tanto el error en training como en validation
son altos, ya que el modelo asume demasiado sobre la forma
de los datos.
A. Causas
•Modelo demasiado simple (ej. lineal para datos con
relaciones cuadraticas).
•No se utilizan todas las variables relevantes.
•Losfeatures disponibles no son buenos predictores de la
variable objetivo.
B. Posibles soluciones
•Incrementar la complejidad del modelo (por ejemplo,
pasar de lineal a cuadratico o a un modelo mas flexible).
•Incorporar masfeatures o transformar los existentes.

•Sustituir o recolectar mejores features que representen de
manera adecuada el problema.
IV. A LTAVARIANZA
Se presenta cuando el modelo se ajusta demasiado a los
datos de entrenamiento pero falla al generalizar en el con-
junto de validacion. Esto provoca overfitting , donde pequeñas
variaciones en los datos de entrada pueden generar malas
predicciones.
A. Causas
•El modelo es demasiado complejo y aprende patrones
irrelevantes o ruido.
•Exceso de dimensionalidad: agregar muchas variables
aumenta el riesgo de overfitting.
•Muy pocos ejemplos en el conjunto de entrenamiento,
especialmente en problemas con clases desbalanceadas.
B. Posibles soluciones
•Reducir la complejidad del modelo (ej. usar menos capas
o un modelo mas simple).
•Disminuir la dimensionalidad eliminando variables irrel-
evantes.
•Obtener mas ejemplos de entrenamiento para mejorar la
representacion de todas las clases.
•Aplicar tecnicas de regularizacion que penalizan la com-
plejidad del modelo, como:
–L1 y L2 (penalizacion sobre los parametros).
–Dropout (apagar ciertas neuronas durante el entre-
namiento).
V. R EGRESIONLOGISTICA
Aunque su nombre incluya “regresion”, la regresion
logistica es un modelo de clasificacion, no de regresion.
Se utiliza principalmente para problemas binarios , donde las
etiquetas ytoman los valores 0o1.
A. Diferencia con la regresion lineal
•Enregresion lineal se predicen valores continuos en los
reales ( R).
•Enregresion logistica se predice la probabilidad de
pertenecer a una clase u otra. El resultado final es una
clasificacion:0o1.
Por ejemplo, con una variable como el tamaño de una
calabaza:
•Regresion lineal: predice el precio aproximado en valores
reales.
•Regresion logistica: predice si la calabaza es naranja ( 1)
o no lo es ( 0).
Fig. 7. Regresion lineal vs logistica
B. Distribucion de Bernoulli
Cada etiqueta yies una variable aleatoria que sigue una
distribucion de Bernoulli. La probabilidad de que ocurra el
evento ( y= 1) o no ocurra ( y= 0) se define como:
P(Y=k) =pk(1−p)1−k, k∈ {0,1}
donde:
•pes la probabilidad deexito ( y= 1).
•kes la etiqueta observada (0 o 1).
Asi, si k= 1 , la probabilidad es p; y si k= 0 , la
probabilidad es 1−p.
VI. F UNCIONSIGMOIDE
La funcion sigmoide es una herramienta clave porque intro-
duce no linealidad al modelo y tiene un rango de salida entre
0 y 1 , lo cual la hace ideal para trabajar con probabilidades.
Se define como:
σ(x) =1
1 +e−x
Al tomar valores de entrada muy negativos, la salida se
acerca a 0; mientras que con valores grandes y positivos, se
acerca a 1.
Fig. 8. Grafica de la funcion sigmoide
Ademas, el argumento xpuede ser cualquier valor o incluso
otra funcion (composicion de funciones), lo que da flexibilidad
para modelar relaciones mas complejas.

La idea es tomar la salida de un modelo lineal y conver-
tirla en una probabilidad. Si partimos de una funcion lineal
fw,b(x) =wx+b, al aplicarle la funcion sigmoide obtenemos:
y=σ(fw,b(x)) =1
1 +e−(wx+b)
De esta forma:
•Siy <0.5, se clasifica como 0.
•Siy≥0.5, se clasifica como 1.
Esto convierte la regresion logistica en un modelo de
clasificacion binaria . Queremos hacerlo asi porque calcular
una funcion lineal es simple computacionalmente, es un buen
metodo para mantener la relacion entre variables y pesos y
permite modelar problemas con mayor complejidad.
A. Diagrama Computacional de la Regresion Logistica
Fig. 9. Diagrama
1) Los inputs (features) xingresan junto con un vector de
pesos wy un biasb.
2) Se calcula el producto punto entre el vector xy el vector
w.
3) Se le aplica la funcion no lineal σ(z), obteniendo como
salida una probabilidad.
4) Finalmente, esta probabilidad se compara con un umbral
para asignar una etiqueta de clase ( 0o1).
En algunos textos, al valor lineal z=wx+bse le
llama pre-activacion, y a la aplicacion de la sigmoide se le
llama activacion. La salida de la activacion corresponde a la
probabilidad estimada y.
B. Optimizacion
Nuestro objetivo es optimizar los parametros wybpara que
el modelo aprenda correctamente. Tenemos:
y=σ(fw,b(x)) =1
1 +e−(wx+b)
Para ajustar los parametros, necesitamos calcular las
derivadas parciales de la funcion de perdida respecto a wy
b. Sin embargo, antes de derivar, debemos definir una funcion
de perdida adecuada.En regresion lineal usamos el error cuadratico medio
(MSE) , pero en clasificacion esto deja de serutil, porque ya
no predecimos valores continuos, sino probabilidades .
El procedimiento general sigue siendo el mismo:
•Definimos una funcion de perdida Lapropiada para
probabilidades.
•Calculamos sus derivadas respecto a wyb.
•Usamos esas derivadas en el algoritmo de descenso del
gradiente , iterando sobre los datos de entrenamiento para
ir actualizando los parametros y minimizar la perdida.
C. Derivada de la funcion sigmoide
σ(x) =1
1 +e−x
σ′(x) =1′·(1 +e−x)−1·(1 +e−x)′
(1 +e−x)2
σ′(x) =e−x
(1 +e−x)2
σ′(x) =e−x+ 1−1
(1 +e−x)2
σ′(x) =e−x+ 1
(1 +e−x)2−1
(1 +e−x)2
σ′(x) =1
1 +e−x−1
(1 +e−x)2
σ′(x) =1
1 +e−x·
1−1
1 +e−x
σ′(x) =σ(x) (1−σ(x))
D. Hallar la funcion de perdida
¿MSE? Esto y mas en la siguiente clase.
VII. C ONCLUSION
En esta clase se reforzaron conceptos esenciales para
comprender como los modelos de aprendizaje supervisado
aprenden a partir de datos. Se revisaron las limitaciones de
la regresion lineal y los problemas comunes asociados al
sesgo y la varianza, asi como tecnicas para evaluar y mejorar
la generalizacion de los modelos. Ademas, se introdujo la
regresion logistica como un modelo de clasificacion, desta-
cando el papel de la funcion sigmoide y su derivada en el
proceso de optimizacion. Estos fundamentos sientan la base
para profundizar en funciones de perdida especificas y en el
entrenamiento de modelos mas complejos en futuras sesiones.

REFERENCIAS
[1] IEEE Costa Rica. “IngenIEEEria Costa Rica.” [En linea]. Disponible:
https://r9.ieee.org/costarica/ingenieeeria
[2] A. Shervine. “Hoja de referencia de Aprendizaje Au-
tomatico.” Stanford University. [En linea]. Disponible:
https://stanford.edu/ ∼shervine/l/es/teaching/cs-229/
hoja-referencia-aprendizaje-automatico-consejos-trucos