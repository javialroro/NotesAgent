Inteligencia Artificial
Apuntes de Clase — 21 de octubre de 2025
1stKendall Rodriguez Camacho
Escuela de Ingenieria en Computacion
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
Kenrodriguez@estudiantec.cr
Abstract—El presente documento contiene los apuntes de la
clase del martes 21 de octubre de 2025, que cubren conceptos
clave sobre los Modelos de Lenguaje Extensos (LLMs). Los
apuntes explican como los LLMs representan el conocimiento
mediante embeddings y espacios vectoriales, e introducen tecnicas
como Retrieval-Augmented Generation (RAG) y agentes in-
teligentes que amplian las capacidades de los LLMs con infor-
macion externa y acciones autonomas.
I. INTRODUCCION
Los Modelos de Lenguaje Extensos (LLMs) han transfor-
mado la interaccion con la inteligencia artificial gracias a
su capacidad para generar texto coherente, traducir idiomas,
redactar codigo y analizar informacion compleja. Su fun-
cionamiento se basa en la representacion numerica de palabras
y frases en espacios vectoriales, donde los embeddings cap-
turan relaciones semanticas y contextuales.
Si bien los LLMs ofrecen capacidades sorprendentes, su
conocimiento es limitado a los datos de entrenamiento y
carecen de habilidades para actuar o buscar informacion acti-
vamente. Para superar estas limitaciones, se han desarrollado
enfoques como Retrieval-Augmented Generation (RAG), que
enriquece las respuestas con informacion externa relevante en
tiempo real, y agentes inteligentes basados en LLMs, capaces
de razonar, planificar y ejecutar tareas autonomas.
Este documento explora estos metodos y su evolucion,
mostrando como se puede pasar de modelos pasivos a sistemas
que no solo comprenden el lenguaje, sino que tambien inter-
actuan con el entorno, toman decisiones informadas y aplican
conocimiento actualizado.
II. ASPECTOS DELCURSO
A. Calendario previsto para el resto del curso
La siguiente Tabla I muestra la planificacion de las ac-
tividades restantes del curso, indicando las fechas y tareas
correspondientes para cada semana.
Nota: En caso de que no se realice la visita a Microsoft, la
clase”Riesgos de IA”se trasladaria al jueves de la semana 15,
y el examen se aplicaria el jueves 20 de noviembre (semana
16).TABLE I
CALENDARIO PREVISTO PARA EL RESTO DEL CURSO
Semana Martes Jueves
12 Asignacion de Tarea 04 (Agentes) Clase de Quantization
13 Quiz 6, Terminar tema Quantiza-
tion, Empezar Unsupervised Learn-
ing y PCAClase Unsupervised Learning y En-
trega Proyecto 01
14 Revision de Proyecto 01 de forma
presencial (se sacara cita en un
forms)Entrega de Tarea 04 (Agentes) y
continuar con revision de Proyectos
15 Clase virtual, se asigna Proyecto 02
y Tarea 05 sobre QuantizationRevision tarea 04 (Agentes) de
forma Virtual
16 Clase Riesgos de IA Visita a Microsoft
17 - -
18 Examen presencial Entrega de Proyecto 02
B. Asignacion de Tarea 04
Se asigna la Tarea 04, la cual consiste en desarrollar un
asistente conversacional que se desempeñe ante diferentes
preguntas basadas en una base de documentos (Apuntes de
clase realizados por los estudiantes hasta la fecha).
Se requiere implementar tecnicas de recuperacion y au-
mento de contexto (RAG) y comparar empiricamente los
resultados con distintos esquemas de segmentacion del texto.
La fecha de entrega esta prevista para el jueves 6 de
noviembre.
III. FUNDAMENTOS DE LOSLLMS
A. Funcionamiento general
Los LLMs procesan los datos de entrada transformandolos
en representaciones numericas que describen caracteristicas
semanticas. Cada palabra, simbolo o caracter se convierte en
una secuencia de valores numericos mediante la tokenizacion,
para luego ser procesados en redes neuronales profundas con
millones o miles de millones de parametros.
B. Del lenguaje al numero
El texto debe convertirse en representaciones numericas para
ser interpretado por el modelo. El proceso de tokenizacion
divide el texto en unidades minimas llamadastokens(palabras,
subpalabras o caracteres), asignando a cada una un identifi-
cadorunico. Estos identificadores se transforman en vectores
que los modelos utilizan como entrada.

TABLE II
TIPOS DE TOKENIZACION
Tipo Ejemplo Ventaja principal
Por palabra ”Los modelos” Simplicidad
Por caracter “H”, “o”, “l”, “a” Sin palabras fuera del
vocabulario (OOV)
Subpalabra (BPE, WordPiece) “Compu”, “tadora” Equilibrio entre vocab-
ulario y contexto
Byte-level Codigo ASCII o UTF-8 Soporta cualquier
simbolo o idioma
Espacios en blanco ”Hola”, ”mundo” Rapido y simple
Fig. 1. Representacion de tokens en un espacio bidimensional y ejemplo de
operaciones semanticas.
IV. REPRESENTACION DELCONOCIMIENTO
A. Tokenizacion
En los LLMs se utilizan distintos enfoques de tokenizacion,
cada uno con caracteristicas particulares que afectan el
rendimiento del modelo: La Tabla II resume estos enfoques,
sus ejemplos y ventajas principales.
B. Representacion en espacios vectoriales
Una vez tokenizado el texto, los identificadores se trans-
forman en vectores dentro de un espacio continuo de alta
dimension. Las palabras con significados similares se ubican
proximas entre si, mientras que las palabras con significados
distintos aparecen mas alejadas.
Esto permite medir similitud semantica y realizar opera-
ciones vectoriales, como analogias entre conceptos, suma o
resta de vectores.
Tal como se muestra en la Figura 1, los vectores representan
tokens proyectados en un espacio bidimensional para facilitar
la comprension, ilustrando relaciones semanticas entre ellos.
Por ejemplo, la conocida analogia:
Rey−Hombre+Mujer≈Reina.
En la practica, estos vectores existen en un espacio de alta
dimension (n dimensiones), lo que permite capturar de manera
mas precisa la informacion semantica y contextual de las
palabras.
Fig. 2. Proceso de generacion de embeddings desde palabra, oracion o
documento hasta el espacio vectorial.
C. Formulas de similitud entre vectores
Para comparar la similitud o distancia entre vectores, se uti-
lizan diversas formulas matematicas, entre las mas comunes:
•Distancia euclidiana: mide la separacion entre puntos en
el espacio. Para dos vectoresa,b∈Rn:
d(a,b) =vuutnX
i=1(ai−bi)2
•Similitud del coseno: mide elangulo entre vectores y su
orientacion en el espacio, siendo la mas usada en modelos
de lenguaje:
sim(a,b) =a·b
∥a∥∥b∥
D. Embeddings
Losembeddingsson representaciones numericas densas que
capturan el significado semantico y las relaciones contextuales
de palabras, oraciones o documentos completos. Estos vectores
permiten comparar ideas, medir similitud y realizar opera-
ciones semanticas en un espacio continuo de alta dimension.
El proceso de generacion de embeddings se puede resumir
en los siguientes pasos:
•Entrada textual: La unidad de texto que se quiere rep-
resentar, que puede ser una palabra, una oracion o un
documento completo.
•Modelo de embeddings: Un modelo que transforma la
entrada en un vector numerico denso, capturando su
significado y contexto.
•Embedding resultante: El vector que representa la en-
trada en el espacio continuo. Vectores cercanos indican
conceptos semanticamente similares.
•Espacio de embeddings: El espacio vectorial donde cada
embedding ocupa una posicion. Este espacio permite
medir similitudes y realizar busquedas por proximidad.
Como se ilustra en la Figura 2, la figura representa el flujo
de generacion de embeddings: desde palabras, oraciones o
documentos de entrada, pasando por el modelo de embeddings,
hasta el vector resultante y su posicion en el espacio de
embeddings.
Ademas, la Figura 3 muestra un ejemplo simplificado de
sentence embeddingsproyectados en un plano bidimensional,
donde frases con significado similar aparecen proximas entre
si.

Fig. 3. Ejemplo de sentence embeddings en un espacio bidimensional
V. CAPACIDADES YLIMITACIONES
A. Capacidades emergentes
Gracias a su entrenamiento masivo y al uso de arquitecturas
basadas entransformers, los LLMs presentan capacidades
como:
•Compresion textual: Interpretan el significado de palabras
y frases segun el entorno en el que aparecen.
•Generacion coherente de texto: Pueden redactar, traducir
o resumir informacion manteniendo estilo y consistencia.
•Razonamiento y planificacion: Resuelven problemas, ex-
plican pasos y trazan estrategias simples.
•Aprendizaje en el prompt: Adaptan su comportamiento a
partir de ejemplos dados en la misma conversacion (in-
context learning).
•Multitarea: Realizan traduccion, clasificacion, codifi-
cacion, analisis o dialogo sin requerir entrenamiento
adicional.
B. Limitaciones
A pesar de sus capacidades, los LLMs presentan limita-
ciones importantes:
•Alucinaciones: Pueden generar respuestas incorrectas o
inventadas, especialmente cuando la informacion de en-
trada es ambigua o insuficiente.
•Memoria limitada: Olvidan informacion que se encuentra
fuera del contexto actual, no recordando interacciones
previas a menos que se almacenen externamente.
•Conocimiento estatico: No tienen acceso a informacion
posterior a su fecha de corte de entrenamiento, por lo que
no estan actualizados en tiempo real.
•Altos costos computacionales: Requieren hardware espe-
cializado y significativos recursos para entrenamiento e
inferencia eficiente, lo que puede limitar su uso practico.
VI. RETRIEVAL-AUGMENTEDGENERATION(RAG)
Dadas las limitaciones de los LLMs tradicionales, los en-
foques deRetrieval-Augmented Generation (RAG)entran en
escena. El enfoque RAG potencia los LLMs conectandolos
con un modulo de recuperacion de informacion (retriever)que inyecta conocimiento externo relevante en tiempo real.
Esto permite generar respuestas mas precisas y coherentes,
accediendo a informacion actualizada y fundamentada.
A. Preparacion de los documentos
Los documentos que se desean utilizar para la recuperacion
se dividen en fragmentos llamadoschunks, normalmente de
entre 200 y 500 tokens. Para evitar perdida de informacion,
los chunks suelen tener unoverlapentre si.
1) Chunking de tamaño fijo:Se segmentan los documentos
en trozos de longitud fija, respetando en la medida de lo
posible los limites de las frases, y se mantiene unoverlap
para preservar contexto.
2) Chunking recursivo:En este enfoque, los chunks no
se cortan estrictamente segun el tamaño maximo, sino que
se ajustan para mantener la semantica de las oraciones. Se
comparan oraciones con la similitud del coseno y, si son
suficientemente similares segun un umbral, se combinan en un
chunk mas grande, logrando un almacenamiento mas eficiente
y contextual.
B. Transformacion en embeddings
Cadachunkse convierte en un vector mediante un modelo
de embeddings. Estos vectores se utilizan para medir similitud
semantica y permitir la recuperacion eficiente de fragmentos
relevantes durante la consulta del usuario.
C. Indexacion
Los vectores resultantes se almacenan en bases vectoriales
especializadas, que pueden residir en memoria RAM o disco:
•FAISS: principalmente en RAM, rapido para busquedas.
•Qdrant: almacenamiento en disco con soporte de
busqueda vectorial.
•Pinecone: almacenamiento en disco y nube, escalable.
Se almacena ademas la metadata asociada, como el texto
original del chunk, para permitir una recuperacion eficiente.
D. Consulta o recuperacion
Cuando llega una pregunta del usuario, el proceso consiste
en:
1) Transformar la consulta en unembedding.
2) Calcular la similitud con todos los embeddings indexa-
dos.
3) Seleccionar lostop-kchunks mas cercanos
semanticamente.
E. Augmentacion y generacion
Para enriquecer el prompt del LLM, los chunks recuperados
se organizan en una plantilla estructurada, que combina el
contextextraido de los documentos con laquestiondel usuario.
Esta plantilla asegura que el modelo reciba toda la informacion
relevante de manera coherente, permitiendole generar respues-
tas precisas y fundamentadas.
A modo de ejemplo, la Figura 4 muestra la estructura
de la plantilla, donde se pueden observar sus componentes
principales:prompt,contextyquestion.

Fig. 4. Estructura de un documento RAG
Fig. 5. Diagrama del flujo deRAGmostrando la preparacion de documentos,
generacion de embeddings, indexacion, recuperacion y generacion de respues-
tas.
F . Beneficios de RAG
•Reduccion de alucinaciones.
•Actualizacion continua con informacion reciente.
•Eficiencia en costos y tiempo de respuesta.
•Aplicabilidad en dominios especializados con infor-
macion privada.
G. Aplicaciones de RAG
•Asistentes empresariales enriquecidos: pueden consultar
documentacion interna y responder de forma precisa.
•Investigacion: lectura automatica de papers, resumenes y
citas.
•Soporte al cliente: analisis de tickets previos para generar
respuestas coherentes y rapidas.
La Figura 5 ilustra el flujo general de un sistema RAG,
donde se integran la creacion de embeddings, la indexacion y
la busqueda vectorial para enriquecer las respuestas generadas
por el LLM.
Si bien los RAG mejoran significativamente el rendimiento
de un LLM tradicional al proporcionarle informacion externa
y actualizada, estos sistemas siguen siendo pasivos: no pueden
buscar activamente informacion en la web ni tomar decisiones
autonomas. Su funcion se limita a complementar la respuesta
del LLM con los datos recuperados.
VII. DELLMS A AGENTES INTELIGENTES
Losagentes basados en LLMsrepresentan un paso mas alla
de los RAGs. Mientras que los RAGs solo enriquecen respues-
tas con informacion recuperada, los agentes pueden razonar,planificar y actuar de manera autonoma, ejecutando tareas en
el mundo real, como consultar APIs, buscar informacion o
tomar decisiones basadas en conocimiento externo.
Esta capacidad se estructura en tres componentes princi-
pales:
A. Memoria
La memoria permite al agente mantener coherencia y con-
texto a lo largo de la interaccion:
•Corto plazo: ventana de contexto del modelo.
•Largo plazo: bases de datos externas, incluyendo sistemas
RAG donde la informacion se divide enchunksy se
representan comoembeddingspara su recuperacion.
B. Planificacion
La planificacion dota al agente de la habilidad de descom-
poner problemas complejos y razonar sobre multiples pasos:
•Chains of Thought (CoT):razonamiento secuencial paso
a paso.
•Trees of Thought (ToT):exploracion de multiples posibles
caminos de razonamiento antes de tomar decisiones.
C. Accion
Finalmente, la accion permite al agente ejecutar tareas
concretas y aplicar su razonamiento en el mundo real:
•Utilizacion de herramientas externas, como buscadores,
APIs o sistemas RAG.
•Enriquecimiento de respuestas con informacion recuper-
ada en tiempo real, basada enchunksde documentos
relevantes.
VIII. CONCLUSION
Los Modelos de Lenguaje Extensos (LLMs) han revolu-
cionado el procesamiento del lenguaje natural, permitiendo
tareas complejas como la generacion de texto coherente, el
razonamiento contextual y la ejecucion multitarea sin necesi-
dad de reentrenamiento.
El uso deembeddingsy espacios vectoriales permite que
los LLMs comprendan relaciones semanticas profundas. Adi-
cionalmente, tecnicas como Retrieval-Augmented Generation
(RAG) mejoran su precision y acceso a informacion actual-
izada, mientras que los agentes inteligentes basados en LLMs
les permiten actuar de manera autonoma, planificar y utilizar
herramientas externas, superando la pasividad de los modelos
tradicionales.
A pesar de estas mejoras, los LLMs y sus extensiones en-
frentan limitaciones importantes, como memoria finita, costos
computacionales elevados y riesgo de alucinaciones. Por ello,
su implementacion requiere un diseño cuidadoso y un uso
responsable, asegurando que sus capacidades se aprovechen
de manera eficiente y confiable.