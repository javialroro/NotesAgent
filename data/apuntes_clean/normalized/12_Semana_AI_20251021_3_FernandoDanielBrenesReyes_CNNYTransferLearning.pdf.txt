Apuntes semana 12 - Modelos de Lenguaje
Extensos y Sistemas Avanzados
(LLMs, RAG y Agentes Inteligentes)
Fernando Daniel Brenes Reyes
Escuela de Ingenieria en Computacion
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
21 de octubre
2020097446@estudiantec.cr
Resumen—El presente documento contiene un repaso y am-
pliacion de los conceptos fundamentales de los Modelos de
Lenguaje Extensos (LLMs), su representacion del conocimiento
mediante la tokenizacion y los embeddings en espacios vec-
toriales. Se detalla la evolucion del LLM tradicional hacia
arquitecturas avanzadas como Retrieval-Augmented Generation
(RAG), que resuelve las limitaciones de conocimiento estatico, y
los Agentes Inteligentes, que integran memoria, planificacion y la
capacidad de ejecutar acciones autonomas, reflejando el estado
del arte en la inteligencia artificial contextual y adaptable.
Index Terms—LLM, RAG, Agentes Inteligentes, Tokenizacion,
Embeddings, Aprendizaje Contextual.
I. INTRODUCCION
LosModelos de Lenguaje Extensos (LLMs)se han
consolidado como la base de los sistemas modernos deInte-
ligencia Artificial Generativa (IAG). Estos modelos no solo
generan texto, sino que tambien permiten la comprension y el
razonamiento sobre texto, codigo y otra informacion compleja.
Aunque son potentes, los LLMs poseen un conocimiento
limitado a sus datos de entrenamiento (estatico) y pueden
incurrir enalucinaciones. Para superar estas barreras, se han
desarrollado enfoques como Retrieval-Augmented Generation
(RAG) y los Agentes Inteligentes.
II. FUNDAMENTOS DELLMS YREPRESENTACION
II-A. Tokenizacion: De la Palabra al Numero
Para que los LLMs puedan computar con el lenguaje,
el texto de entrada debe convertirse en una representacion
numerica. El proceso deTokenizaciontransforma palabras,
signos o simbolos en unidades minimas llamadastokens,
asignando a cada una unID numericounico.
Existen multiples estrategias de tokenizacion, cada una
optimizada para un objetivo distinto:
Por palabra: Ofrece simplicidad.
Por caracter: Permite manejar simbolos o palabras fuera
del vocabulario (OOV).
Subpalabra (BPE, WordPiece): Logra un equilibrio
optimo entre el tamano del vocabulario y la preservacion
del contexto.II-B. Embeddings y Espacios Vectoriales
Una vez tokenizados, los IDs numericos se convierten en
embeddings, que son representaciones numericas densas en
un espacio continuo de alta dimension.
Captura semantica: Los embeddings capturan el sig-
nificado y las relaciones contextuales entre palabras u
oraciones completas.
Proximidad: Las palabras con significados similares se
ubican proximas en el espacio vectorial.
Operaciones: Este espacio permite realizar operacio-
nes semanticas, como analogias (por ejemplo,Rey−
Hombre+Mujer≈Reina).
Para medir lasimilitudentre dos vectoresaybenRn, la
Similitud del Cosenoes la metrica mas utilizada:
sim(a,b) =a·b
||a||||b||(1)
Figura 1. Representacion tridimensional de tokens (Realeza).

II-C. Capacidades Emergentes
El entrenamiento masivo de los LLMs les confiere capa-
cidades avanzadas queemergensin haber sido entrenados
directamente para ellas:
Razonamiento y planificacion.
Aprendizaje en el prompt(In-context Learning): Adap-
tan el comportamiento a partir de ejemplos dados en la
entrada.
Multitarea: Realizan traduccion, clasificacion y codifi-
cacion sin reentrenamiento.
III. RETRIEVAL-AUGMENTEDGENERATION(RAG)
RAG es un paradigma que conecta un LLM con un mo-
dulo de recuperacion (retriever) para inyectarconocimiento
externo, actualizado y verificabledurante la generacion de
respuestas.
III-A. Proceso y Flujo de RAG
1.Preparacion (Chunking): Los documentos se dividen
en fragmentos (chunks), que suelen contener entre200
y 500 tokens, a menudo conoverlappara preservar el
contexto.
2.Indexacion: Cadachunkse convierte en unembedding
y se almacena en unabase de datos vectorial(por
ejemplo, FAISS, Qdrant, Pinecone).
3.Consulta y recuperacion: La pregunta del usuario se
transforma en unembedding, se calcula la similitud
con los vectores indexados y se seleccionan lostop-k
chunksmas cercanos semanticamente.
4.Aumento y generacion: Loschunksrecuperados se
integran en una plantilla estructurada (prompt) como
contexto adicional, asegurando que la respuesta del
LLM sea precisa y fundamentada.
III-B. Ventajas y Limitaciones
RAG ofrece lareduccion de alucinaciones, laactua-
lizacion continua del conocimientoy la aplicabilidad en
dominios especializados. No obstante, los sistemas RAG si-
guen siendopasivos; su funcion se limita a complementar la
respuesta del LLM con datos recuperados.
Figura 2. Diagrama del flujo de un sistema RAG, desde la indexacion hasta
la generacion de la respuesta.
Figura 3. Agente inteligente.
IV. DELLMAAGENTEINTELIGENTE
LosAgentes Inteligentesbasados en LLMs superan la
pasividad de los sistemas RAG. Estos agentes puedenrazonar,
planificaryactuarde manera autonoma, interactuando con
el mundo real mediante herramientas externas.
IV-A. Componentes Clave del Agente
1.Memoria: Permite mantener coherencia y contexto a lo
largo del tiempo.
Corto plazo: Ventana de contexto del modelo.
Largo plazo: Bases de datos externas, incluyendo
sistemas RAG para la recuperacion contextual.
2.Planificacion: Permite descomponer problemas comple-
jos en pasos y razonar sobre ellos.
Chains of Thought (CoT): Razonamiento secuen-
cial.
Trees of Thought (ToT): Exploracion de multiples
caminos de razonamiento antes de decidir.
3.Accion: Capacidad de ejecutar tareas concretas median-
teherramientas externas(APIs, buscadores, sistemas
RAG). Por ejemplo, un agente puede acceder a un
sistema de recursos humanos para responder: “¿Cuantos
dias de vacaciones me quedan?”.
IV-B. Escalamiento Responsable
La implementacion de agentes requiere evaluar cuando es
necesaria la complejidad de un sistema multiagente. Es crucial
garantizar laseguridad,privacidady eluso eticode los
datos, disenando los agentes bajo principios de transparencia
y responsabilidad.
REFERENCIAS
[1] Pacheco Portuguez, S. (2025).Presentacion del curso de Inteligencia
Artificial. Instituto Tecnologico de Costa Rica.