Apuntes de clase: Redes Neuronales
Brandon Emmanuel Sanchez Araya
Escuela de Ingenieria en Computacion
Instituto Tecnologico de Costa Rica
Cartago, Costa Rica
brandon01sanchez@estudiantec.cr
23 Setiembre 2025
Abstract—Este documento presenta una formalizacion de
apuntes de clase correspondientes al curso de Inteligencia Arti-
ficial. Se abordan los conceptos fundamentales de la regresion
logistica (binaria y multiclase), el uso del dataset MNIST y
la representacion de imagenes medianteflatten. Asimismo, se
introduce la codificacionone–hot, la formulacion matricial con
pesos y sesgos, y la relacion de estos modelos con la construccion
de redes neuronales. Finalmente, se destacan las propiedades
esenciales de las redes, como la no linealidad, la organizacion en
capas y su capacidad para resolver problemas complejos a traves
de la optimizacion por gradiente.
I. ELDATASETMNIST
El datasetMNIST(Modified National Institute of Standards
and Technology) es uno de los conjuntos de datos mas famosos
en elarea de aprendizaje automatico. Fue creado a partir de
la recopilacion de miles de digitos manuscritos provenientes
de estudiantes de secundaria y empleados de la Oficina del
Censo de los Estados Unidos. La idea original era disponer de
un conjunto estandarizado que sirviera para probar y comparar
algoritmos de reconocimiento de escritura.
•Conjunto de imagenes: digitos escritos a mano (del 0 al
9).
•Tamaño original:128×128pixeles.
•Tamaño transformado:28×28pixeles.
•Flatten: cada imagen se convierte en un vector de784
caracteristicas.
•1 Channel: un solo canal, es decir en blanco y negro.
•Cantidad de ejemplos: 60,000 para entrenamiento y
10,000 para prueba.
En la Figura 1 se muestra un ejemplo de como un digito
manuscrito se representa en MNIST como una matriz de28×
28pixeles, que luego puede convertirse en un vector de784
caracteristicas (flatten).
.
II. ¿COMO DISEÑAR UN PROGRAMA QUE RECONOZCA
TODOS LOS NUMEROS QUE LAS PERSONAS PUEDEN HACER?
A. Pixeles activos e inactivos & formacion de la figura
En una imagen de MNIST, cada pixel tiene una intensidad
(0 = “apagado”, valores altos = “encendido”). La figura del
digito se forma por elpatronde pixeles activos/inactivos. El
aprendizaje consiste en ajustar pesos para que ciertas config-
uraciones de pixeles (patrones) produzcan la clase correcta.
Fig. 1. Ejemplo de representacion de un digito en MNIST y sus pixeles en
escala de grises.
B. Por que esto es un problema complejo
Aunque un digito “5” tiene una forma reconocible, cada
persona lo escribe distinto. La variacion en trazo, grosor,
inclinacion y ubicacion hace que sea dificil usar reglas fijas;
necesitamos un modelo que aprenda a partir de ejemplos.
C. Clasificacion binaria: “¿es un 5 o no?”
La regresion logistica es la base de las redes neuronales. Se
usa para clasificar entre dos clases (ej: ¿es un 5 o no lo es?).
fw,b(x) =1
1 +e−(wx+b)
h(x) =g(f(x))
g(x) =1
1 +e−x
fw,b(x) =wx+b
En la Figura 2 se observa como la regresion logistica puede
interpretarse como una red neuronal muy simple.

fInput layer (x∈R784)
Outputy∈(0,1)
Fig. 2. Modelo de regresion logistica como red neuronal: entradas→
combinacion lineal→funcion sigmoide.
D. ¿Como alimentar una regresion logisticacon una matriz?
SeaX∈R28×28la imagen (matriz de pixeles). Se aplana
(flatten) en un vector columna:
x= vec(X)∈R784.
Tamaño de entrada (input layer) y conteo de parametros
•Input layer:784features(un pixel por entrada).
•Pesos en binario:784pesos enw+1bias =785
parametrosen total.
III. REGRESIONLOGISTICAMULTINOMIAL
(EXPERIMENTO EN CLASE)
Ejercicio del profe: 10 regresiones que responden “si/no”
Se eligio a 10 estudiantes, cada uno “especialista” en un
digito (0–9). Cada imagen se le pregunta a los especialista
uno por uno y ellos respondieron “si es mi numero” o “no
es”. Si la respuesta no coincide con la etiqueta verdadera, se
hace refuerzo (entrenamiento). Como resultado se obtiene:
One–hot vector
La etiqueta correcta se codifica como un vector con ununico
1 en la posicion del digito correcto:
0 1 2 3 4 5 6 7 8 9
y (one–hot) 0 010 0 0 0 0 0 0
Ese1marca cual estudiante (regresion) deberia decir “si”.
La Figura 3 representa la extension al caso multinomial.
En este modelo, las entradas se conectan directamente con
multiples salidas, de manera que cada una corresponde a
una clase distinta. De esta forma se pueden reconocer si-
multaneamente los diez digitos de MNIST.Capa de entrada (R5)Capa de salida (R10)
Fig. 3. Regresion logistica multinomial: 5 entradas conectadas directamente
con 10 salidas.
Compactacion: de 10 vectores a una sola matriz
En vez de calcular 10 regresiones por separado, apilamos
sus pesos en una matriz:
W|{z}
∈R10×784=
−
w⊤
0
−
−
w⊤
1
−
...
−
w⊤
9
−
, b|{z}
∈R10=
b0
b1
...
b9
, z=Wx+b|{z}
∈R10.
´Indices:W j,ies el peso que conecta elfeaturei(pixeli) con
la neurona/clasej.
•Miwes una matrizW∈R10×784.
•Mibes un vectorb∈R10(un bias por neurona/clase).
¿Que sucede con el parametrob?
Cada neurona/clase tiene su propio sesgo:b=
(b0, . . . , b 9)⊤.Cantidad de neuronas=tamaño deb.
IV. EJERCICIO:DE VECTOR A MATRIZ
1) Una sola regresion binaria (vectorx)
Sea
x=
3
4
5
6
, w=
3
2
4
5
, b= 2.

Entonces
z=w⊤x+b= [ 3 2 4 5 ]
3
4
5
6
+2 = 67+2 = 69,y=σ(z).
2) Varias regresiones a la vez
Ahora dos regresiones (piensa “dos neuronas de salida”).
Apilamos sus pesos en una matrizWy sus sesgos en un
vectorb:
W=3 2 4 5
4 3 2 1
∈R2×4, b=2
3
∈R2.
Con el mismoxde arriba:
z=Wx+b=3 2 4 5
4 3 2 1
3
4
5
6
+2
3
=69
43
.
V. REDNEURONAL
Una red neuronal es un modelo matematico inspirado en
el funcionamiento del cerebro humano. Esta compuesta por
unidades llamadas neuronas, organizadas en capas. Las capas
estan conectadas entre si, de manera que la salida de una capa
sirve como entrada de la siguiente.
Propiedades clave
•No linealidad: permite resolver problemas complejos que
un modelo lineal no podria.
•Capas: la profundidad de la red es un hiperparametro
que define su capacidad, y en cada una de las capas hay
neuronas.
•Diferenciabilidad: cada capa debe ser diferenciable para
que podamos optimizar mediante gradiente descendente.
•Optimizacion: si puedo derivar, puedo optimizar.
Cuando aplicamos una red neuronal despues de un clasi-
ficador multinomial, la logica cambia respecto a una clasifi-
cacion binaria tradicional. En una clasificacion binaria simple,
la relacion es lineal entre las entradas (features) y la salida. En
una red neuronal, la salida ya no depende directamente de la
imagen original, sino de las activaciones de la capa anterior.
Estructura tipica
•Capa de entrada: es la que recibe directamente los datos
del problema. Cada neurona de esta capa representa una
caracteristica (feature) de la entrada. Por ejemplo, en el
caso de MNIST cada pixel de la imagen se convierte en
una neurona de la capa de entrada.
•Capas intermedias (ocultas): son las que procesan la
informacion recibida. Aqui la red va combinando y
transformando los datos para encontrar patrones mas
abstractos. Se llaman “ocultas” porque no interactuan con
el mundo exterior: solo comunican informacion entre la
entrada y la salida.
•Capa de salida: es la que entrega el resultado final del
modelo. Dependiendo del problema, puede ser una solaneurona (para decidir entre dos clases, por ejemplo “si”
o “no”) o varias neuronas (para elegir entre multiples
categorias, como los 10 digitos en MNIST).
Profundidad y complejidad
Entre mas capas profundas tenga la red, mas puede “des-
menuzar” el problema en representaciones intermedias, lo
que le permite identificar patrones complejos que una simple
regresion logistica no podria capturar.
En la Figura 4 se muestra un ejemplo de red neuronal con
tres entradas, una capa oculta de cinco neuronas y cuatro
salidas. Este esquema ilustra como la introduccion de capas in-
termedias permite transformar las representaciones y capturar
relaciones no lineales mas complejas en los datos.
Capa de entradaCapa oculta
Capa de salida
Fig. 4. Red neuronal pequeña: 3 entradas, 1 capa oculta de 5 neuronas y 4
salidas.
VI. CONCLUSIONES
El estudio de la regresion logistica permite comprender
los cimientos de las redes neuronales modernas. A partir de
problemas de clasificacion binaria simples se llega de manera
natural a la extension multiclase, donde se introducen la for-
mulacion matricial y la codificacionone–hot. Estos elementos
muestran como multiples regresiones pueden integrarse en un
solo modelo mas general.
El concepto de red neuronal surge al conectar varias de
estas operaciones en capas sucesivas, incorporando funciones
de activacion no lineales que amplian la capacidad de rep-
resentacion. La diferenciabilidad de cada capa asegura la
posibilidad de entrenar el modelo mediante optimizacion,
mientras que la profundidad incrementa su habilidad para
capturar patrones complejos. En sintesis, las redes neuronales
son una evolucion directa de la regresion logistica, potenciadas
por la organizacion en capas y la introduccion de no linealidad.