Una herramienta mencionada por el profesor es Weights
and Biases, la cual es una herramienta de seguimiento y
visualizacion de experimentos de Machine Learning donde
nosotros ejecutamos un entrenamiento y vemos en tiempo real
desde cualquier computador como se esta comportando un
modelo. La ventaja es que podemos ver el comportamiento
por lo que podemos detenerlo si no vemos buenos resultados. El procesamiento de imagenes puede ser algo pesado por
lo que debemos reducir el tamaño de estas a un tamaño de
224x224. Esto debido a que computacionalmente se vuelve
costoso. No se pueden utilizar librerias comoResNetque sirven para
abstraer la definicion de capas mas alla de torch.nn. El profesor nos recomienda buscar una herramienta en
redes neuronales que nos pueda hacer toda la arquitectura
del modelo. Incluso esta se puede hacer en PyTorch, queda
a nuestra disposicion. Tenemos dos modelos:
•LeNet-5 clasico:Este es la arquitectura mas basica
(como el profesor lo menciona) para el procesamiento
de imagenes el cual fue creado por Yann LeCun. •Arquitectura alternativa:Esta esta basada en literatura
la cual implementa cualquier arquitectura distinta. Podemos escoger diferentes espectrogramas como por ejem-
plo, el Data Augmentation el cual trata de aumentar los datos
de entrenamiento para mejorar la generalizacion de mi modelo
con la finalidad de obtener mejores patrones. En el paper SpecAugment, que sale en la bibliografia del
proyecto, propone 3 tipos de tecnicas:
•Time Masking:Donde tomo una frecuencia del 1 al 1.5
donde hago una mascara para cancelar el ruido
•Time Warping:Para estirar o encoger
•Frequency Masking:Que aplica mascaras similares pero
en el eje de la frecuencia, lo que simula la perdida o
interferencia de ciertas bandas del espectro de audio
El entrenamiento se debe realizar varias veces por lo que
se debe dejar todo montado y conectado la herramienta
de Weights and Biases. Esto porque el entrenamiento con
imagenes puede ser pesado, requiere de GPU.