3) Principales Arquitecturas:
a) LeNet-5:Propuesta porYann LeCunen 1998, fue
una de las primeras redes convolucionales aplicadas al re-
conocimiento de digitos escritos a mano [1]. Su estructura
incluye dos capas convolucionales, dos depoolingy una
totalmente conectada, estableciendo la base para las redes
modernas de vision por computadora. b) AlexNet:Desarrollada porKrizhevsky, Sutskevery
Hintonen el 2012, marco el inicio delDeep Learningmod-
erno. Procesa imagenes de224×224con filtros grandes
(11×11,5×5,3×3), emplea activacionesReLU,dropout
y entrenamiento distribuido en multiples GPUs, logrando un
salto significativo en precision sobre el conjunto ImageNet.c) ZFNet:Creada en base a AlexNet, ajusta el tamaño
de los filtros y la profundidad para estudiar como cada capa
transforma la informacion. Introdujo tecnicas para visualizar
activaciones intermedias, ayudando a comprender y depurar el
comportamiento interno de las CNN. d) GoogleNet (Inception):Presentada por Google en
2014, redujo de 60 a 4 millones de parametros mediante los
modulosInception, que combinan convoluciones de distintos
tamaños (1×1,3×3,5×5) ymax poolingen paralelo. En
la etapa final, unaverage poolingglobal transforma el tensor
de7×7×1024en un vector1×1×1024, reemplazando las
capas densas y mejorando la eficiencia [2]. e) VGG16:Simplifica el diseño utilizando solo filtros
pequeños de3×3y bloques repetidos de convolucion ypool-
ing. Aumenta la profundidad hasta 16 o 19 capas, mostrando
que mas capas con filtros simples mejoran el rendimiento
general. f) ResNet:Introduce lasconexiones residuales, que per-
miten que la informacion fluya entre capas no consecutivas. Estas conexiones evitan el desvanecimiento del gradiente y
posibilitan entrenar redes extremadamente profundas de forma
estable. g) DenseNet:Conecta cada capa con todas las anteriores
dentro de un bloque, promoviendo la reutilizacion de carac-
teristicas y reduciendo la redundancia.