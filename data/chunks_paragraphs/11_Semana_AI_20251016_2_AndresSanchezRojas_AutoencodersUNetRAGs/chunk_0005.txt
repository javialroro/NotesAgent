Un agente integra recuperacion, gestion del contexto y conec-
tores a herramientas externas para resolver tareas complejas
de forma autonoma.VI. TOKENIZACION YEMBEDDINGS
VI-A. Tokenizacion
La tokenizacion convierte texto en secuencias de identifica-
dores. Estrategias comunes de tokenizacion son: por palabra,
por subword, por caracter, por bytes. Cada estrategia tiene
trade-offs en cobertura, eficiencia y manejo de formas raras. VI-B. Embeddings
Los embeddings son vectores densos que representan tokens
o secuencias en un espacio donde la proximidad indica similitud
semantica. Al agregar embeddings de tokens (por ejemplo
mediante promedio o modelos que producen representaciones
de secuencia) se obtienen vectores de frases/consultas utiles
para busquedas semanticas y recuperacion en RAGs, y como
entrada para razonamiento en agentes. VII. CONCLUSIONES
Los puntos vistos en esta clase y resumidos en este docu-
mento ofrecen una sintesis compacta de conceptos relevantes
en autoencoders, variational autoencoders, segmentacion de
imagenes con arquitecturas como U-Net, y RAGs y agentes
basados en LLMs. Estos avances han permitido la expansion
del uso de la inteligencia artificial en ambientes en los que
antes no se hubiera considerado util. Sin embargo, debemos ser
responsables al decidir quetareas realmente requieren un agente
o pueden usar un sistema mas ligero de machine learning.