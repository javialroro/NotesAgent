El profesor enfatizo que, a diferencia
de los modelos de clasificacion, los autoencoders no utilizan
etiquetas externas, sino que aprenden de los propios datos,
permitiendo capturar patrones y regularidades internas. Durante el repaso, se analizo la estructura general de un
autoencoder compuesta por unencoder, unespacio latente
y undecoder. El encoder transforma la entrada en una
representacion de menor dimensionalidad que concentra la in-
formacion esencial; el decoder, a su vez, reconstruye la imagen
a partir de esa representacion. Este proceso de codificacion
y decodificacion se comparo con una forma de “compresion
aprendida” donde el modelo decide que informacion conservar
y cual descartar.El profesor destaco ademas las aplicaciones practicas re-
visadas: la reduccion de dimensionalidad como alternativa a
metodos tradicionales, la deteccion de anomalias mediante
el analisis del error de reconstruccion, y la restauracion de
imagenes afectadas por ruido o baja resolucion. Finalmente,
se repaso el concepto deespacio latente continuo, introducido
en los autoencoders variacionales (V AE), el cual permite ge-
nerar nuevas muestras mediante la interpolacion entre puntos
del espacio latente, estableciendo asi la base para los modelos
generativos que se profundizarian en la sesion actual. III. APUNTES DE CLASE
III-A. Organizacion y avisos
Las revisiones del proyecto seran presenciales, el pro-
fesor aviso a los apuntadores faltantes que lo tomen en
cuenta ya que una semana se debera de apartar para la
revision del proyecto. Proximamente habra dos entregables principales: un ejer-
cicio practico con autoencoders (imagenes) y una tarea
mas compleja sobre texto y agentes, esta puede que
valga mas porcentaje. Ya que esta implica planificar
experimentos y validaciones con tiempo para revisiones
en laboratorio.