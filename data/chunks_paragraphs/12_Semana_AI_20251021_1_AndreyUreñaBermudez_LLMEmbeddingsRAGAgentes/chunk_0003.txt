Tabla I
TIPOS COMUNES DE TOKENIZACION Y SUS PRINCIPALES VENTAJAS. Tipo EjemploVentaja princi-
pal
Palabra “Los medios” Simplificada
Caracter “L”, “o”, “s” Sin OOVs
Subpalabra (BPE,
WordPiece)“super” + “vivencia”Equilibra vocab-
ulario/contexto
Byte-level bytes UTF-8Soporta cualquier
simbolo
Espacio en blanco “Hola”, “mundo” Rapido y simple
Tras la tokenizacion, los tokens se representan como vec-
tores en un espacio continuo. Esto permite medir similitud
semantica entre palabras. C. Metricas de similitud
Las metricas mas utilizadas incluyen:
•Distancia euclidiana:mide que tan separados estan dos
puntos en el espacio vectorial. •Similitud del coseno:
Sim(a, b) =a·b
||a||||b||
Evalua elangulo entre los vectores; unangulo menor
implica mayor similitud. Tabla II
EJEMPLO SIMPLIFICADO DE TOKENIZACION:LAS PALABRAS SE
TRANSFORMAN EN TOKENS CON IDENTIFICADORES NUMERICOS. Palabra Token ID Numerico
Los los 105
LLM llm 2124
aprenden aprenden 893
patrones patrones 5749
D. Embeddings
Losembeddingsson representaciones numericas densas que
asignan a cada token un vector en un espacio continuo de
alta dimension. Capturan significado semantico y relaciones
contextuales entre palabras u oraciones completas, permitiendo
comparaciones mas profundas entre ideas o documentos. E. Capacidades de los LLM
Debido a su entrenamiento a gran escala y arquitecturas
basadas en Transformers, los LLM presentan capacidades
emergentes:
•Comprension contextual. •Generacion coherente de texto. •Razonamiento y planificacion basica. •Aprendizaje en el prompt (in-context learning). •Multitarea sin reentrenamiento. •Conocimiento estatico derivado de los datos de entre-
namiento. •Costos computacionales elevados.IV. MATERIA NUEVA: RETRIEVAL-AUGMENTED
GENERATION(RAG)
Un sistema RAG conecta un LLM con un modulo
de recuperacion de informacion (retriever) para incorporar
conocimiento externo relevante durante la generacion de re-
spuestas. A.