Repaso de Algebra Lineal y Aprendizaje
Supervisado
Instituto Tecnologico de Costa Rica
Escuela de Ingenieria en Computacion
Inteligencia Artificial
Mariana Quesada Sanchez
19 de agosto de 2024
Abstract — This paper reviews concepts of linear algebra
relevant to artificial intelligence, including vectors, norms,
distances, dot product, orthogonality, and orthonormality. It
also introduces the principles of supervised learning, describing
datasets as feature–label pairs and distinguishing between
regression and classification tasks through illustrative examples. I. INTRODUCTION
El algebra lineal es la base para representar datos en
espacios multidimensionales y para definir operaciones que
permiten medir magnitudes, direcciones y similitudes. Estos
fundamentos son indispensables en algoritmos de machine
learning, en particular dentro del aprendizaje supervisado,
donde los datos se representan como vectores de caracteris-
ticas asociados a etiquetas. II. ALGEBRA LINEAL
A. Vectores
Un vector se define como una entidad matematica car-
acterizada por magnitud y direccion. En espacios de dos
o tres dimensiones, puede visualizarse como un segmento
orientado que parte del origen y termina en un punto (x,y,z) . En espacios de dimension n, se representa como una tupla
ordenada (x1, x2, . . . , x n). Los vectores constituyen la base
de la representacion de datos en espacios multidimensionales
y permiten operaciones como la suma, la resta y la multipli-
cacion por escalares. El desplazamiento de un vector se define como la difer-
encia entre un punto final B= (b1, b2, . . . , b n)y un
punto inicial A= (a1, a2, . . . , a n). Formalmente, el vector
desplazamiento se expresa como
AB=B−A= (b1−a1, b2−a2, . . . , b n−an),
lo cual indica cuanto debe recorrerse en cada componente
para pasar de AaB. Por ejemplo, si A= (1,2)yB= (4,6),
entonces AB= (3,4), lo que representa un movimiento de
tres unidades en el eje xy cuatro en el eje y.