P ROCEDIMIENTO DE QUANTIZATION EN MODELOS DE
REDES NEURONALES
Pasos generales del procedimiento:
•Transformacion de pesos: Los pesos de la red, original-
mente en formato de punto flotante (float), se convierten
a valores enteros mediante mapas de cuantizacion queasignan rangos de valores flotantes a niveles discretos
enteros. •Cuantizacion de entradas: Las entradas a cada capa
tambien se convierten a enteros para mantener la coheren-
cia en la representacion y facilitar operaciones eficientes. •Cuantizacion del sesgo (bias): Los terminos de sesgo,
que son sumados en cada neurona, se transforman de
float. •Normalizacion del rango: Se definen valores maximos y
minimos para pesos, entradas y sesgos, que corresponden
a los valores limite de la representacion entera (por
ejemplo, el rango de int8). Esto asegura que los valores
cuantizados esten dentro de rangos representables. •Calculo en espacio entero: Las operaciones de la capa
(multiplicacion y suma) se realizan en enteros, generando
un vector cuantizado. •Des-cuantizacion:Despues de la capa, los valores en-
teros se convierten nuevamente a punto flotante para
continuar con el procesamiento de modo que las capas
siguientes no requieren conocer el esquema de cuanti-
zacion aplicado. Durante la dequantization es donde puede ocurrir perdida de
precision, ya que la conversion entre representaciones intro-
duce aproximaciones. Sin embargo, el objetivo es que la salida
cuantizada sea lo suficientemente cercana a la original para no
afectar el rendimiento del modelo. Este proceso es beneficioso
ya que permite que modelos originalmente pesados funcionen
eficientemente con menor consumo de memoria y tiempo
de computo, esencial sistemas embebidos o con capacidad
limitada. Es importante aclara que las capas que siguen a una
capa cuantizada generalmente no requieren modificaciones ni
conocen directamente la cuantizacion aplicada, manteniendo
transparencia en la mayoria de frameworks. VI.