Para esto, evaluamos como cada
parametro afecta la perdida utilizando derivadas parciales con
respecto a wyb. Considerando la funcion de perdida basada en el error
cuadratico medio (MSE) para nuestro modelo lineal fw,b(x) =
wx+b, tenemos:
L(w, b) =1
NNX
i=1((wxi+b)−yi)2
Las derivadas parciales de Lcon respecto a wybse
calculan como:
∂L
∂w=2
NNX
i=1((wxi+b)−yi)xi
∂L
∂b=2
NNX
i=1((wxi+b)−yi)
Estas derivadas nos indican la direccion y magnitud del
ajuste necesario para cada parametro, permitiendo aplicar
algoritmos de optimizacion como el gradient descent para
actualizar wyb. B. Epoch
Una epoch es una iteracion completa sobre todo el conjunto
de entrenamiento. Es un hiperparametro que define cuantas ve-
ces se recorrera el dataset completo durante el entrenamiento,
por ejemplo, epochs = 5 . Si tenemos 10 000 muestras y ejecutamos 5 epochs, signi-
fica que se procesaran todas las muestras 5 veces en total. La
actualizacion de los parametros puede realizarse al finalizar
cada epoch o de manera mas frecuente utilizando batches. C. Batch
Unbatch es un subconjunto del conjunto de entrenamiento
que se utiliza para calcular la gradiente y actualizar los
parametros del modelo. Por ejemplo, si tenemos 10 000 muestras y un batch
size = 1 000 , necesitaremos 10 batches para completar