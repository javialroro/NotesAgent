Fig. 3. Ejemplo de sentence embeddings en un espacio bidimensional
V. CAPACIDADES YLIMITACIONES
A. Capacidades emergentes
Gracias a su entrenamiento masivo y al uso de arquitecturas
basadas entransformers, los LLMs presentan capacidades
como:
•Compresion textual: Interpretan el significado de palabras
y frases segun el entorno en el que aparecen. •Generacion coherente de texto: Pueden redactar, traducir
o resumir informacion manteniendo estilo y consistencia. •Razonamiento y planificacion: Resuelven problemas, ex-
plican pasos y trazan estrategias simples. •Aprendizaje en el prompt: Adaptan su comportamiento a
partir de ejemplos dados en la misma conversacion (in-
context learning). •Multitarea: Realizan traduccion, clasificacion, codifi-
cacion, analisis o dialogo sin requerir entrenamiento
adicional. B. Limitaciones
A pesar de sus capacidades, los LLMs presentan limita-
ciones importantes:
•Alucinaciones: Pueden generar respuestas incorrectas o
inventadas, especialmente cuando la informacion de en-
trada es ambigua o insuficiente. •Memoria limitada: Olvidan informacion que se encuentra
fuera del contexto actual, no recordando interacciones
previas a menos que se almacenen externamente. •Conocimiento estatico: No tienen acceso a informacion
posterior a su fecha de corte de entrenamiento, por lo que
no estan actualizados en tiempo real. •Altos costos computacionales: Requieren hardware espe-
cializado y significativos recursos para entrenamiento e
inferencia eficiente, lo que puede limitar su uso practico. VI. RETRIEVAL-AUGMENTEDGENERATION(RAG)
Dadas las limitaciones de los LLMs tradicionales, los en-
foques deRetrieval-Augmented Generation (RAG)entran en
escena. El enfoque RAG potencia los LLMs conectandolos
con un modulo de recuperacion de informacion (retriever)que inyecta conocimiento externo relevante en tiempo real. Esto permite generar respuestas mas precisas y coherentes,
accediendo a informacion actualizada y fundamentada. A.