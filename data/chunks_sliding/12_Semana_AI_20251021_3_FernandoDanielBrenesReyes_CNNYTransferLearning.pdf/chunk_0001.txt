Apuntes semana 12 - Modelos de Lenguaje Extensos y Sistemas Avanzados (LLMs, RAG y Agentes Inteligentes) Fernando Daniel Brenes Reyes Escuela de Ingenieria en Computacion Instituto Tecnologico de Costa Rica Cartago, Costa Rica 21 de octubre 2020097446@estudiantec.cr Resumen—El presente documento contiene un repaso y am- pliacion de los conceptos fundamentales de los Modelos de Lenguaje Extensos (LLMs), su representacion del conocimiento mediante la tokenizacion y los embeddings en espacios vec- toriales. Se detalla la evolucion del LLM tradicional hacia arquitecturas avanzadas como Retrieval-Augmented Generation (RAG), que resuelve las limitaciones de conocimiento estatico, y los Agentes Inteligentes, que integran memoria, planificacion y la capacidad de ejecutar acciones autonomas, reflejando el estado del arte en la inteligencia artificial contextual y adaptable. Index Terms—LLM, RAG, Agentes Inteligentes, Tokenizacion, Embeddings, Aprendizaje Contextual. I. INTRODUCCION LosModelos de Lenguaje Extensos (LLMs)se han consolidado como la base de los sistemas modernos deInte- ligencia Artificial Generativa (IAG). Estos modelos no solo generan texto, sino que tambien permiten la comprension y el razonamiento sobre texto, codigo y otra informacion compleja. Aunque son potentes, los LLMs poseen un conocimiento limitado a sus datos de entrenamiento (estatico) y pueden incurrir enalucinaciones. Para superar estas barreras, se han desarrollado enfoques como Retrieval-Augmented Generation (RAG) y los Agentes Inteligentes. II. FUNDAMENTOS DELLMS YREPRESENTACION II-A. Tokenizacion: De la Palabra al Numero Para que los LLMs puedan computar con el lenguaje, el texto de entrada debe convertirse en una representacion numerica. El proceso deTokenizaciontransforma palabras,