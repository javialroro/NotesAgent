Componentes Principales (PCA, por sus siglas en ingles: Principal Component Analysis) es un metodo estadistico ampliamente utilizado para la reduccion de dimensionalidad, que transforma un conjunto de vari- ables posiblemente correlacionadas en un nuevo conjunto de variables no correlacionadas denominadas componentes principales. El procedimiento consiste en centrar los datos, calcular la matriz de covarianza, obtener sus autovalores y autovectores, y seleccionar los vectores asociados a los mayores autovalores para proyectar los datos en un subespacio de menor dimension que conserva la mayor varianza posible de la informacion original [10], [11], [12]. B. Comportamiento Jerarquico Los humanos aprenden cosas simples para transformarlo en algo mas complejo, tal es el caso del MLP conformado por multiples regresiones lineales, de lo cual se optienen ganan- cias exponenciales en algunas funciones, como polinomios, la composicion de funciones que permite reusar funciones simples otras de orden superior y que mediante una repre- sentacion compacta, en la que pocos pesos se pueden modelar funciones complejas, como por ejemplo, una red neuronal que se aproxime a otra. VI. C ONCLUSION La clase permitio la comprension de los fundamentos de las redes neuronales, resaltando su estructura jerarquica al final y las motivaciones biologicas que inspiran su arquitectura. A partir del analisis del perceptron y de sus limitaciones, se introdujo la necesidad de arquitecturas mas complejas, como el MLP, que posibilitan la resolucion de problemas no lineales. Esta sesion trato tanto el potencial como los desafios de las redes