Figura 3: Matriz de pesos Wen la capa fully connected: cada fila corresponde a una neurona de salida y cada columna a un pixel de entrada.4.2Ejemplo Numerico de Clase: De Vector a Matriz V.B.1. Calculo de una sola regresion (vector de 4 features): w= 3 2 4 5 , b= 2, x= 3 4 5 6 . z=w⊤x+b= (3·3) + (2·4) + (4·5) + (5·6) + 2 = 69. y=σ(z). V.B.2. Calculo de varias regresiones a la vez (2 neuronas): W=3 2 4 5 4 3 2 1 , b=2 3 , x= 3 4 5 6 . z=Wx+b=69 43 . 5Arquitectura de las Redes Neuronales Profun- das 5.1 Definicion y Estructura Tipica Unared neuronal artificiales un modelo de computo inspirado en el cerebro humano, compuesto por unidades llamadasneuronas artificiales. Cada neurona recibe un conjunto de entradas x, aplica una combinacion lineal con sus pesos wy un sesgo b, y luego pasa el resultado por una funcion de activaciong: h(x) =g(w⊤x+b). Capa de entrada:recibe los 784 pixeles (flatten). Capas ocultas:transforman la informacion en re- presentaciones abstractas. Capa de salida:entrega la prediccion (10 neuronas para MNIST). Figura 4: Ejemplo esquematico de una red neuronal con capa de entrada, capa(s) oculta(s) y capa de salida. 2 5.2 El Rol del Sesgob Retomando, el parametro b(bias o sesgo) podriamos verlo como undesplazamientoen la funcion de acti- vacion. Sin b, todas las funciones aprendidas por la red tenderian a pasar por el origen, lo