ejemplo anterior de 12 elementos, a un tensor bidimensional de 3 filas por 4 columnas •torch.zeros((z,x,y)) / torch.ones((z,x,y)) / torch.grandn(x,y) Se utilizan para crear tensores de diferentes dimensiones, relleno con ceros, unos o numeros random •Operaciones elemento a elemento pytorch permite op- eraciones aritmeticas entre tensores las cuales se aplicaran elemento a elemento •Concatenaciones de tensores Mediante torch.cat((X.Y),dim=k se pueden concatenar tensores, siendo k el eje donde sobre el que se apilaran •Indexacion logica Mediante X==Y siendo X y Y ten- sores se pueden realizar mascaras booleanas XII. C REACION DESDE LISTAS DE PYTHON A= torch.tensot([[2,1,4,3], [1,2,3,4], [4,3,2,1]], dtype=torch.float32) A tensor([[2.,1.,4.,3.], [1.,2.,3.,4.], [4.,3.,2.,1.]]) XIII. I NDEXACION Y SEGMENTACION(SLICING ) fila_ultima = A[-1] # ltima fila de X submatriz = A[1:3] # Filas 1 y 2 de X fila_ultima, submatriz XIV. B ROADCASTING El broadcasting en tensores permite operar tensores de diferentes formas al expandir automaticamente, a = torch.arange(3).reshape((3, 1)) # Forma 3 x1 b = torch.arange(2).reshape((1, 2)) # Forma 1 x2 broadcast = a + b # Resultado de forma 3x2 gracias al broadcasting XV. O PERACIONES IN-PLACE Se indica que se tiene que tener cuidado debido a que cuando se tratan con modelos de machine learning o deep learning, nos encontramos con el hecho de que se ocupa muchisima memoria y hay que procurar seroptimos en este sentido y al hacer ejecutar operaciones se puede dejar memoria asignada o se apunta a nuevas secciones de memoria, lo cual puede