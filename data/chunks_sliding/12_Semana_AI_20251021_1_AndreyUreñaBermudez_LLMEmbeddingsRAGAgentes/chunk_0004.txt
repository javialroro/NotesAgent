dimension. Capturan significado semantico y relaciones contextuales entre palabras u oraciones completas, permitiendo comparaciones mas profundas entre ideas o documentos. E. Capacidades de los LLM Debido a su entrenamiento a gran escala y arquitecturas basadas en Transformers, los LLM presentan capacidades emergentes: •Comprension contextual. •Generacion coherente de texto. •Razonamiento y planificacion basica. •Aprendizaje en el prompt (in-context learning). •Multitarea sin reentrenamiento. •Conocimiento estatico derivado de los datos de entre- namiento. •Costos computacionales elevados.IV. MATERIA NUEVA: RETRIEVAL-AUGMENTED GENERATION(RAG) Un sistema RAG conecta un LLM con un modulo de recuperacion de informacion (retriever) para incorporar conocimiento externo relevante durante la generacion de re- spuestas. A. Chunks El texto se divide en fragmentos denominadoschunks, que suelen contener entre 200 y 500 tokens. Cada fragmento se transforma en un vector mediante un modelo de embeddings, capturando su significado semantico. B. Consulta o recuperacion Dada una consulta, el sistema convierte la pregunta en un embedding y calcula la similitud con los embeddings indexados, devolviendo los mas cercanos semanticamente. C. Aumento y generacion Los fragmentos recuperados se integran en el prompt envi- ado al LLM, proporcionando contexto adicional que guia la respuesta hacia informacion verificada y relevante. D. Ventajas principales •Reduccion de alucinaciones. •Actualizacion continua del conocimiento. •Eficiencia de costos en entrenamiento. •Aplicabilidad en dominios especializados. •Asistentes empresariales enriquecidos. •Soporte a la investigacion y atencion al cliente. V. LLMTRADICIONAL VSAGENTE INTELIGENTE Un LLM tradicional puede ofrecer informacion general, pero carece de personalizacion y accion. Por ejemplo,