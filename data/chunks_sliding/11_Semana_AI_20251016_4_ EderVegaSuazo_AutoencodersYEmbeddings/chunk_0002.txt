y visualizaciones de espacios latentes. II. REPASO DE LA CLASE La sesion inicio con un repaso de los temas vistos ante- riormente, en los que se introdujeron los fundamentos de los autoencoders y su relacion con las redes convolucionales. Se recordo que estas arquitecturas son una aplicacion directa de las CNN en un contexto no supervisado, donde el objetivo principal es reconstruir la entrada original a partir de una repre- sentacion comprimida. El profesor enfatizo que, a diferencia de los modelos de clasificacion, los autoencoders no utilizan etiquetas externas, sino que aprenden de los propios datos, permitiendo capturar patrones y regularidades internas. Durante el repaso, se analizo la estructura general de un autoencoder compuesta por unencoder, unespacio latente y undecoder. El encoder transforma la entrada en una representacion de menor dimensionalidad que concentra la in- formacion esencial; el decoder, a su vez, reconstruye la imagen a partir de esa representacion. Este proceso de codificacion y decodificacion se comparo con una forma de “compresion aprendida” donde el modelo decide que informacion conservar y cual descartar.El profesor destaco ademas las aplicaciones practicas re- visadas: la reduccion de dimensionalidad como alternativa a metodos tradicionales, la deteccion de anomalias mediante el analisis del error de reconstruccion, y la restauracion de imagenes afectadas por ruido o baja resolucion. Finalmente, se repaso el concepto deespacio latente continuo, introducido en los autoencoders variacionales (V AE), el cual permite ge- nerar nuevas muestras mediante la interpolacion entre puntos