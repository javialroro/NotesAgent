Apuntes semana 11 Clase #2 Eder Vega Suazo Escuela de Ingenieria en Computacion Instituto Tecnologico de Costa Rica IC-6200 - Inteligencia Artificial Gr2 Resumen—Este documento condensa la segunda leccion de la semana 11 centrada en autoencoders y su aplicacion a imagenes y texto. Se explican la estructura encoder–espacio latente–decoder, variantes practicas (denoising, V AE, under/overcomplete) y ar- quitecturas relacionadas (U-Net, skip-connections). Se discuten tareas y aplicaciones: reduccion de dimensionalidad, deteccion de anomalias, super-resolucion y segmentacion, ademas de la transicion a representaciones de texto (tokenizacion y embed- dings) y modelos de lenguaje. El apunte incluye recomendaciones experimentales y criterios de evaluacion practicos orientados a la implementacion de proyectos y a la replicacion de resultados. Index Terms—Autoencoder, V AE, Denoising, Reduccion de dimensionalidad, Tokenizacion, Embeddings, U-Net, Deteccion de anomalias. I. INTRODUCCION Este documento sintetiza los conceptos trabajados en la sesion sobre arquitecturas basadas en redes convolucionales aplicadas a autoencoders y la extension hacia representacio- nes para texto. El documento ofrece una guia practica con definiciones, formulas y recomendaciones operativas para la implementacion de experimentos en imagenes y texto. Se su- giere acompañar este documento con las figuras referenciadas para facilitar la comprension de arquitecturas y visualizaciones de espacios latentes. II. REPASO DE LA CLASE La sesion inicio con un repaso de los temas vistos ante- riormente, en los que se introdujeron los fundamentos de los autoencoders y su relacion con las redes convolucionales. Se recordo que estas arquitecturas son una aplicacion directa