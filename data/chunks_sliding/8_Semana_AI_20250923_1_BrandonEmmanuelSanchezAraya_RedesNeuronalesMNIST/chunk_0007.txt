solaneurona (para decidir entre dos clases, por ejemplo “si” o “no”) o varias neuronas (para elegir entre multiples categorias, como los 10 digitos en MNIST). Profundidad y complejidad Entre mas capas profundas tenga la red, mas puede “des- menuzar” el problema en representaciones intermedias, lo que le permite identificar patrones complejos que una simple regresion logistica no podria capturar. En la Figura 4 se muestra un ejemplo de red neuronal con tres entradas, una capa oculta de cinco neuronas y cuatro salidas. Este esquema ilustra como la introduccion de capas in- termedias permite transformar las representaciones y capturar relaciones no lineales mas complejas en los datos. Capa de entradaCapa oculta Capa de salida Fig. 4. Red neuronal pequeña: 3 entradas, 1 capa oculta de 5 neuronas y 4 salidas. VI. CONCLUSIONES El estudio de la regresion logistica permite comprender los cimientos de las redes neuronales modernas. A partir de problemas de clasificacion binaria simples se llega de manera natural a la extension multiclase, donde se introducen la for- mulacion matricial y la codificacionone–hot. Estos elementos muestran como multiples regresiones pueden integrarse en un solo modelo mas general. El concepto de red neuronal surge al conectar varias de estas operaciones en capas sucesivas, incorporando funciones de activacion no lineales que amplian la capacidad de rep- resentacion. La diferenciabilidad de cada capa asegura la posibilidad de entrenar el modelo mediante optimizacion, mientras que la profundidad incrementa su habilidad para capturar patrones complejos.