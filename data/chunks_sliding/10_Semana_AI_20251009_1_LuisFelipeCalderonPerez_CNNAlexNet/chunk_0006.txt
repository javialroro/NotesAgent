la formula de3≥n≥0. III-A. ¿Que arquitectura preferimos? Se prefiere a las arquitecturas con convoluciones pequenas, ya que las convoluciones grandes nos llevan a que las neuronas se computen de forma lineal y que la cantidad de pesos sea mayor. III-B. Algunas "reglas" El tamano de la imagen deberia ser divisible por 2. Las convoluciones deben usar campos receptivos peque- nos 3x3, con un stride de 1. Parapooling layer es comunmax poolingde F=2, S=3. s, cantidad de pasos. III-C. Menciones finales Al final se mencionan arquitecturas similares a LeNet para tomar en cuenta para el proyecto, tales como, AlexNet, AFNet, GoogleNet (reduce parametros), VGG16 y ResNet. Nota:Embedding, informacion distribuida en espacio vec- torial que retorna mi NN. REFERENCIAS [1] “ResNet, AlexNet, VGGNet, Inception: Understanding various archi- tectures of Convolutional Networks,” CV-Tricks.com, Aug. 01, 2022. https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/ [2] R. R. Abril, “Redes convolucionales,” La Maquina Oraculo, Jul. 2025, [Online]. Available: https://lamaquinaoraculo.com/deep-learning/redes- neuronales-convolucionales/ [3] S. A. P. Portuguez, “Apuntes de la clase de inteligencia artificial,” Cartago, Costa Rica, agosto 2025, clase del 9 de octubre del 2025.