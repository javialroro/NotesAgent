55. Y con la arquitectura de AlexNet 2 obtenemos que aprendimos 96 de profundidad. II-D. Pesos Compartidos Si ya tenemos un filtro que extrae cierta caracteristica, y sirve para una posicion; tambien sirve para otra posicion. Por lo que, vamos a usar el mismo filtro para toda la imagen. II-E. Transfer learning Se menciona que en el paper de AlexNet despues de aplicar su arquitectura y lo referente a ella. Y se dan cuenta que en las primeras capas hay figuras o informacion similar. Por lo que se introduce el termino detransfer learning, que consiste en pasar el peso de las primeras capas a otra red, para ahorrar tiempo de entrenamiento. III. ARQUITECTURASCONVOLUCIONALES Se componen deConvolutional layer,Pooling layery deDense layer. Se deben tomar desiciones sobre nuestra arquitectura, por ejemplo, si la convolucion reduce el input debo decidir si hago o no el pooling. Y estas desiciones determinan el comportamiento del tamano de la imagen, pero si la imagen es muy reducida, le llega poca informacion a lafully connected. Se introdujoel termino de stack, que es, INPUT→[[conv→relu]∗n→Pool?]∗m→[fc→ relu]∗k→fc, m≥0, k≥0, y se menciona que enpapers la cantidad de convoluciones y relu se usa la formula de3≥n≥0. III-A. ¿Que arquitectura preferimos? Se prefiere a las arquitecturas con convoluciones pequenas, ya que las convoluciones grandes nos llevan a que las neuronas se computen de forma lineal y que la cantidad de pesos sea mayor. III-B. Algunas "reglas" El tamano de la imagen deberia