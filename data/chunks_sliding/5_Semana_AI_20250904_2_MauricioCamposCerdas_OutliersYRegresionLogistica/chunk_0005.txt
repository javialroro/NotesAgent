ciertaepoca de entrenamiento, pero luego empieza a sobreajustarse a los datos de entrenamiento, produciendo overfitting. A esta tecnica de detener el entrenamiento antes de que esto suceda se le llama early stopping. •Underfitting: Se da cuando el error es alto tanto en training como en testing. Esto se conoce como under- fitting, que ocurre cuando el modelo no logra ajustarse correctamente a los datos. Es lo opuesto al overfitting y se caracteriza por un alto sesgo. Para ver graficamente estos escenarios, ver Fig. 2). •Bias-Variance Tradeoff: Validacion con buen resultado, pero entrenamiento con alto error. Es raro que suceda y tal vez hay errores de calculo. Fig. 3. Linear vs Logistic Regression E. Alto Bias Cuando el modelo comete muchos errores en el training set, se produce underfitting. Esto ocurre porque el modelo asume demasiado del training set, no utiliza todas los features disponibles y es demasiado simple para capturar la compleji- dad de los datos. Para evitar un alto sesgo, se puede utilizar un modelo mas complejo. Ademas, es importante revisar que los features del training set sean adecuadas para la naturaleza del problema, ya que si no tienen la capacidad de capturar la informacion relevante, el modelo no podra hacer predicciones correctas. F . Alta Varianza Ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento y no es capaz de generalizar correctamente. Esto suele suceder cuando los datos son de alta dimension- alidad y hay