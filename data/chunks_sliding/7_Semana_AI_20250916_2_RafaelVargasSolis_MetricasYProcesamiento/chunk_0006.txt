TP+FN(5) Mide la capacidad del modelo para identificar correctamente los positivos. Importante en contextos donde los falsos nega- tivos son criticos. D. F1-Score F1 =2·Precision ·Recall Precision +Recall(6) Es la media armonica entre precision y recall, usada en casos de desbalance de clases. V. C ASO DE ESTUDIO Se evaluo un modelo de deteccion de cancer con 1000 pacientes. •Clase positiva: 30 pacientes con cancer. •Clase negativa: 970 pacientes sin cancer. Matriz de confusion: Cancer No cancer Cancer 25 (TP) 20 (FP) No cancer 5 (FN) 950 (TN) Resultados: •Accuracy:25+950 1000= 97.5% •Recall:25 25+5= 83.3% •Precision:25 25+20= 55% •F1-Score:2·0.55·0.833 0.55+0 .833≈66.2% A pesar del alto valor de accuracy, las metricas muestran limitaciones en la deteccion de la clase positiva. VI. METRICAS AVANZADAS A. Curva ROC La curva ROC ( Receiver Operating Characteristic ) mues- tra el desempeño de un clasificador binario para distintos umbrales. Representa la Tasa de Verdaderos Positivos (TPR) frente a la Tasa de Falsos Positivos (FPR). Fig. 2. Ejemplo de curva ROC y calculo de AUC. B.´Area Bajo la Curva (AUC) El AUC mide elarea bajo la curva ROC: •AUC = 0.5: clasificador aleatorio. •AUC cercano a 1: modelo con gran poder de discrimi- nacion. VII. P ROCESAMIENTO DE DATOS A. Problemas encontrados en la calidad de datos En escenarios reales, los datos suelen presentar problemas que afectan directamente la efectividad de los algoritmos de mineria y aprendizaje automatico. Los principales son: •Incompletitud: valores faltantes en atributos