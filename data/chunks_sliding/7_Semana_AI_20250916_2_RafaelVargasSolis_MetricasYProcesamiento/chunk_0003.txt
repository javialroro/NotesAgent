magnitud de los valores extremos.De esta manera, se disminuye su influencia en la varianza del modelo y se mejora la distribucion de los datos. •Winsorizacion (recorte): Sustituir los valores atipicos por valores mas cercanos dentro de un rango definido, usualmente basado en percentiles (por ejemplo, 1% y 99%). Esta tecnica conserva la estructura general de los datos y evita que los valores extremos distorsionen los resultados. 3. Mencione dos tecnicas para evitar un alto sesgo y dos para evitar alta varianza. En el aprendizaje automatico, es fundamental lograr un equilibrio entre sesgo yvarianza para obtener modelos con buena capacidad de generalizacion. A continuacion, se de- scriben algunas tecnicas para abordar ambos problemas: Para reducir sesgo (underfitting): •Incrementar la complejidad del modelo: Utilizar mod- elos mas sofisticados, como polinomiales en lugar de lineales, redes neuronales mas profundas o algoritmos no lineales, permite capturar relaciones mas complejas entre las variables. •Incorporar nuevas variables o caracteristicas: Me- diante tecnicas de feature engineering , se pueden in- cluir atributos relevantes que enriquezcan la informacion disponible, mejorando asi la capacidad predictiva del modelo. Para reducir varianza (overfitting): •Aplicar regularizacion: Metodos como L1 (Lasso) y L2 (Ridge) añaden penalizaciones a los coeficientes del modelo, limitando su magnitud y evitando que el modelo se ajuste excesivamente a los datos de entrenamiento. •Aumentar los datos o usar tecnicas de ensamble: Incrementar el tamaño del conjunto de entrenamiento o aplicar metodos como bagging yrandom forest mejora la estabilidad del