imbalanceados pueden producir validation o testing sets con menos datos o ninguno, de las clases menos repre- sentadas. 2) Stratified sampling:Se utiliza para datos imbalanceados ya que asegura una representacion de todas las clases en cada Split. Mantiene la misma distribucion de datos para cada clase en cada subconjunto, lo que da un modelo mas robusto. 3) K-fold Cross-Validation:Se divide el subconjunto en K partes y el modelo se entrena con K-1 partes ya que una se reserva para validacion. Se continua este proceso rotando los subconjuntos usados para el entrenamiento y validacion. Permite tomar el promedio del rendimiento del modelo y esutil cuando tenemos pocos datos y deseamos validar nuestro modelo. Se puede ver de forma mas grafica en la siguiente imagen: F . Posibles escenarios Dentro de los posibles escenarios de estos metodos se encueentran: •Bajo error en training, bajo error en testing. •Escenario ideal. •Modelo evita el ruido existente en los datos. •Puede generalizar correctamente. Visualmente se puede ver de la siguiente forma: Otro escenario es cuando se tiene lo siguiente: •Bajo error en training, alto error en testing. •Overfitting. •No es capaz de generalizar. •Alta varianza. Visualmente se ve de la siguiente forma: Otro escenario es el siguiente: •Alto error en training, alto error en testing. •Underfitting. •El modelo no esta aprendiendo nada de los datos. •Modelo muy simple. •Alto sesgo Visualmente se ve de la siguiente forma: Para solucionar esteultimo caso se utiliza un Bias-Variance