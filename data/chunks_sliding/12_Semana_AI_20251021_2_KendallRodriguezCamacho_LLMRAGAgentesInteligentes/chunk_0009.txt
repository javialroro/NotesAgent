Los vectores resultantes se almacenan en bases vectoriales especializadas, que pueden residir en memoria RAM o disco: •FAISS: principalmente en RAM, rapido para busquedas. •Qdrant: almacenamiento en disco con soporte de busqueda vectorial. •Pinecone: almacenamiento en disco y nube, escalable. Se almacena ademas la metadata asociada, como el texto original del chunk, para permitir una recuperacion eficiente. D. Consulta o recuperacion Cuando llega una pregunta del usuario, el proceso consiste en: 1) Transformar la consulta en unembedding. 2) Calcular la similitud con todos los embeddings indexa- dos. 3) Seleccionar lostop-kchunks mas cercanos semanticamente. E. Augmentacion y generacion Para enriquecer el prompt del LLM, los chunks recuperados se organizan en una plantilla estructurada, que combina el contextextraido de los documentos con laquestiondel usuario. Esta plantilla asegura que el modelo reciba toda la informacion relevante de manera coherente, permitiendole generar respues- tas precisas y fundamentadas. A modo de ejemplo, la Figura 4 muestra la estructura de la plantilla, donde se pueden observar sus componentes principales:prompt,contextyquestion. Fig. 4. Estructura de un documento RAG Fig. 5. Diagrama del flujo deRAGmostrando la preparacion de documentos, generacion de embeddings, indexacion, recuperacion y generacion de respues- tas. F . Beneficios de RAG •Reduccion de alucinaciones. •Actualizacion continua con informacion reciente. •Eficiencia en costos y tiempo de respuesta. •Aplicabilidad en dominios especializados con infor- macion privada. G. Aplicaciones de RAG •Asistentes empresariales enriquecidos: pueden consultar documentacion interna y responder de forma precisa. •Investigacion: lectura automatica de papers, resumenes