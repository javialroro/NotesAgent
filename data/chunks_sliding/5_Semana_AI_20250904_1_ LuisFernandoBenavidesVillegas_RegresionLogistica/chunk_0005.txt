en el dataset original una clase representa el 90% y otra el 10%, esa relacion se conserva en las divisiones. 3) K-Fold Cross-Validation: El conjunto de entrenamiento se divide en Kpartes (folds). En cada iteracion se usa Kâˆ’1folds para entrenar y el fold restante para validar. El proceso se repite Kveces, rotando el fold de validacion. Esto permite aprovechar mejor los datos disponibles y obtener una evaluacion mas robusta del modelo. F . Posibles escenarios de comportamiento de training y vali- dation 1) Overfitting: El error en training es bajo pero el error en validation comienza a aumentar despues de cierto punto. El modelo memoriza los datos de entrenamiento en lugar de aprender patrones generales. Se captura tambien el ruido de los datos, lo que provoca que no pueda generalizar. Se caracteriza por tener alta varianza . Fig. 1. Ej. de overfitting Fig. 2. Ej. de regresion de overfitting Una tecnica para evitarlo es el early stopping , que consiste en detener el entrenamiento en laepoca donde el error de validacion empieza a empeorar. 2) Underfitting: Tanto el error en training como en val- idation son altos. El modelo no logra aprender patrones de los datos porque es demasiado simple o incorrecto para el problema. Se caracteriza por alto sesgo , es decir, asume una forma equivocada de los datos (por ejemplo, usar un modelo lineal para datos con comportamiento cuadratico). Fig. 3. Ej. de underfitting Fig. 4. Ej. de