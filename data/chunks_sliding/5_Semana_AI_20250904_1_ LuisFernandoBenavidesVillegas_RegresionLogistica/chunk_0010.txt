variables y pesos y permite modelar problemas con mayor complejidad. A. Diagrama Computacional de la Regresion Logistica Fig. 9. Diagrama 1) Los inputs (features) xingresan junto con un vector de pesos wy un biasb. 2) Se calcula el producto punto entre el vector xy el vector w. 3) Se le aplica la funcion no lineal σ(z), obteniendo como salida una probabilidad. 4) Finalmente, esta probabilidad se compara con un umbral para asignar una etiqueta de clase ( 0o1). En algunos textos, al valor lineal z=wx+bse le llama pre-activacion, y a la aplicacion de la sigmoide se le llama activacion. La salida de la activacion corresponde a la probabilidad estimada y. B. Optimizacion Nuestro objetivo es optimizar los parametros wybpara que el modelo aprenda correctamente. Tenemos: y=σ(fw,b(x)) =1 1 +e−(wx+b) Para ajustar los parametros, necesitamos calcular las derivadas parciales de la funcion de perdida respecto a wy b. Sin embargo, antes de derivar, debemos definir una funcion de perdida adecuada.En regresion lineal usamos el error cuadratico medio (MSE) , pero en clasificacion esto deja de serutil, porque ya no predecimos valores continuos, sino probabilidades . El procedimiento general sigue siendo el mismo: •Definimos una funcion de perdida Lapropiada para probabilidades. •Calculamos sus derivadas respecto a wyb. •Usamos esas derivadas en el algoritmo de descenso del gradiente , iterando sobre los datos de entrenamiento para ir actualizando los parametros y minimizar la perdida. C. Derivada de la funcion sigmoide σ(x) =1 1