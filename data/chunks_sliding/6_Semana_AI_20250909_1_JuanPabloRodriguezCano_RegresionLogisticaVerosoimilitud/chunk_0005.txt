ecuacion es la probabilidad de que su etiqueta sea yicon los pesos wactuales. Como se quiere optimizar los pesos para los cuales se obtiene una mejor metrica, se debe derivar esta funcion. Sin embargo, existe un problema con esta expresion donde una multiplicacion incluye polinomios muy grandes, y calcular la dervida respectiva se vuelve muy complejo y computacionalmente costoso. Ademas, como se trata de valores probabilisticos, o sea, de 0 a 1, su multiplicacion se vuelve extremadamente pequeña y asi la derivada de la funcion se vuelve virtualmente cero, y esto no cambia los pesos en el paso de entrenamiento. A esto se le conoce como el fenomeno de ”vanishing gradients”. Por esta razon se aplican los teoremas de logaritmo y se obtiene la siguiente expresion. ln(L) =X ln(fw,b(xi)yi+ln((1−fw, b (xi))1−yi) ⇒ln(L) =X yiln(fw,b(xi) + 1−yiln((1−fw, b (xi))) Esto se convierte en una tarea mas facil de optimizacion. Sin embargo, la funcion de logaritmo es estrictamente creciente,por lo que hay que convertir un problema de maximizacion en minimizacion. Para esto, simplemente se da vuelta a la funcion delnmultiplicando por -1.