marco el inicio delDeep Learningmod- erno. Procesa imagenes de224×224con filtros grandes (11×11,5×5,3×3), emplea activacionesReLU,dropout y entrenamiento distribuido en multiples GPUs, logrando un salto significativo en precision sobre el conjunto ImageNet.c) ZFNet:Creada en base a AlexNet, ajusta el tamaño de los filtros y la profundidad para estudiar como cada capa transforma la informacion. Introdujo tecnicas para visualizar activaciones intermedias, ayudando a comprender y depurar el comportamiento interno de las CNN. d) GoogleNet (Inception):Presentada por Google en 2014, redujo de 60 a 4 millones de parametros mediante los modulosInception, que combinan convoluciones de distintos tamaños (1×1,3×3,5×5) ymax poolingen paralelo. En la etapa final, unaverage poolingglobal transforma el tensor de7×7×1024en un vector1×1×1024, reemplazando las capas densas y mejorando la eficiencia [2]. e) VGG16:Simplifica el diseño utilizando solo filtros pequeños de3×3y bloques repetidos de convolucion ypool- ing. Aumenta la profundidad hasta 16 o 19 capas, mostrando que mas capas con filtros simples mejoran el rendimiento general. f) ResNet:Introduce lasconexiones residuales, que per- miten que la informacion fluya entre capas no consecutivas. Estas conexiones evitan el desvanecimiento del gradiente y posibilitan entrenar redes extremadamente profundas de forma estable. g) DenseNet:Conecta cada capa con todas las anteriores dentro de un bloque, promoviendo la reutilizacion de carac- teristicas y reduciendo la redundancia. Esta estructura densa mejora la propagacion del gradiente, optimiza la eficiencia del modelo y mantiene un numero reducido de parametros. II. PROBLEMAS CON LASREDESNEURONALES CONVOLUCIONALES A pesar de su alto desempeño, las redes convolucionales se