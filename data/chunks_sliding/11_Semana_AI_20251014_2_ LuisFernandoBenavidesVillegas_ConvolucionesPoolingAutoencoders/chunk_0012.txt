pequeño produce un modelo mas eficiente en computo, pero con menor capacidad para capturar detalles de la imagen. En cambio, un vector mas grande permite representar mas caracteristicas, aunque incrementa el costo de entrenamiento y de procesamiento. •Numero de capas:tanto el encoder como el decoder pueden variar en profundidad. Un mayor numero de capas permite modelar relaciones mas complejas, pero tambien hace el entrenamiento mas pesado y sensible al ajuste de parametros. •Funcion de perdida:para tareas de reconstruccion de imagenes se utiliza comunmente elMean Squared Error (MSE). Esta funcion compara cada pixel de la imagen original con el de la reconstruccion, midiendo su difer- encia. Un error cercano a cero indica que el modelo ha logrado reproducir correctamente la entrada.IV. CONCLUSIONES Las redes convolucionales permiten extraer automaticamente caracteristicas jerarquicas de las imagenes, impulsando el desarrollo de arquitecturas cada vez mas profundas y eficientes. A pesar de su potencia, siguen siendo poco interpretables, por lo que se recurre a tecnicas de visualizacion y analisis de activaciones. Finalmente, los autoencodersamplian estos conceptos al aprendizaje no supervisado, permitiendo la compresion, reconstruccion y generacion de datos a partir de representaciones latentes. REFERENCIAS [1] Y . LeCun, L. Bottou, Y . Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,”Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, 1998. [2] C. Szegedy et al., “Going deeper with convolutions,”Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1–9, 2015.