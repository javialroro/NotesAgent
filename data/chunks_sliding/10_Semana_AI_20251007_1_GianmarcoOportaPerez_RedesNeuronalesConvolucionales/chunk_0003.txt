muestra corresponde a una grabacion corta etiquetada con su clase correspondiente. Antes del entrenamiento, las señales acusticas son transformadas en representaciones visuales denominadas espectrogramas, las cuales se emplean como entrada a las redes convolucionales. El proyecto requiere la construccion manual de dos modelos empleando PyTorch sin librerias de alto nivel: •Modelo A: Variante clasica de LeNet-5 adaptada al reconocimiento de audio mediante espectrogramas. •Modelo B: Arquitectura alternativa fundamentada en literatura academica o en un diseño propio justificado teoricamente. Se deben generar dos versiones del conjunto de datos: una con los audios transformados a imagenes (base) y otra con versiones aumentadas mediante tecnicas de data augmentation orientadas al dominio del audio. Este proceso busca incremen- tar la robustez del modelo y su capacidad de generalizacion. Durante la fase de entrenamiento se construyen cu- atro combinaciones principales: Modelo A/Base, Modelo A/Aumentado, Modelo B/Base y Modelo B/Aumentado. Cada modelo se entrena con diferentes hiperparametros, evaluando su desempeño con metricas como precision, perdida, F1-Score y matriz de confusion. La herramienta Weights & Biases se utiliza para monitorear y visualizar los resultados durante el entrenamiento. Finalmente, los modelos seleccionados se comparan para determinar el de mejor rendimiento general. El informe debe presentarse en formato IEEE, acompañado del codigo fuente y el cuaderno en Jupyter Notebook. III. A SPECTOS PRACTICOS DEL PROYECTO El desarrollo debe realizarse en PyTorch, construyendo manualmente cada capa de la red. Es necesario registrar todas las metricas relevantes utilizadas en clases anteriores,