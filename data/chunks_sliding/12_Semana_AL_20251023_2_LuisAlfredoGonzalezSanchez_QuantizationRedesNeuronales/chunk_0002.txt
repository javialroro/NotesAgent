modelos, principalmente transformando los datos de punto flotante a formatos de menor precision, como enteros. Esta transformacion permite que los modelos se ejecuten de manera mas rapida y con menor consumo de memoria, lo cual es fundamental para desplegar inteligencia artificial en dispositivos con recursos limitados, como moviles y sistemas embebidos. En el presente documento, se busca resumir la informacion vista en la clase del 23 de octubre,donde se ha revisado como diferentes metodos de cuantizacion —desde la simetrica y asimetrica hasta la dinamica, granulada y post- entrenamiento— manejan la conversion de pesos, activaciones y sesgos, optimizando el balance entre precision y eficiencia. Ademas, se menciona como tecnicas como la cuantizacion consciente durante el entrenamiento (QAT) ayudan a mantener la precision del modelo al considerar el efecto de la cuanti- zacion desde el inicio del aprendizaje. II. B REVE DEFINICION DE ONNIX Para continuar el tema de quantization en supervised learn- ing , es importante entender la herramienta onnix, suponga un modelo llm ya entrenado¿Como empieza a funcionar el producto o sistema? La herramienta Onnix permite representarmodelos de aprendizaje automatico desarrollados en distin- tos frameworks como PyTorch o TensorFlow en una repre- sentacion intermedia estandar y eficiente. Esta representacion facilita la interoperabilidad y el despliegue de modelos en diferentes plataformas y hardware mediante optimizaciones en C++ u otros lenguajes, asegurando que el mismo modelo pueda ejecutarse con alto rendimiento en entornos variados. Considerando lo anterior, las plataformas poseen diversas lim-