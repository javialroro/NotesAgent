que maximiza la eficiencia de recursos y computacion utilizando C++. El mecanismo por el cual se disminuye es la cuantizacion y se enfoca en el hecho que los parametros de los modelos son representados con tipos de datos de punto flotante, se reducen para hacer los modelos mas densos con tecnicas especiales para no afectar mucho la precision de la inferencia. Aunque no es posible no introducir error, es necesario asumir esta desventaja para desplegar los modelos. LLaMA 2 es un modelo muy popular y notorio por tener un tamaño muy grande, tiene 70 mil millones de parametros, cada uno esta representado por un punto flotante de 32 bits, lo que resulta en 28GB que deberian estar en memoria si se quisiera utilizar en una maquina local. Esto claramente no es viable porque la mayoria de maquinas comerciales cuentan con una capacidad menor a eso. Ademas, las opera- ciones que se se hacen con datos de punto flotante son muy lentas en comparacion a datos representados por enteros. La cuantizacion hace una reduccion de los bits requeridos para representar cada parametro y lo convierte a enteros, que se pueden representar en las siguientes configuraciones: 8, 5, 2y hasta 1 bit. La cuantizacion resulta en un menor tiempo de inferencia y menor consumo de energia, ademas de facilitar la opcion de correr estos modelos en sistemas pequeños como dispositivos moviles o sistemas embebidos. A. Representacion de numeros Se suelen utilizar numeros