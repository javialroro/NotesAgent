de Costa Rica, que organiza reuniones periodicas entre distintas universidades. El proposito principal es identificar fuentes de financiamiento para eventos tecnologicos, especialmente aquellos destinados a llevar co- nocimiento a zonas rurales o con menor acceso. Tambien se anunciola realizacion de un taller de team building el domingo 9 de noviembre, con un costo de $20, que incluye almuerzo y transporte. III. TEMA PRINCIPAL: QUANTIZATION Quantization es una tecnica de optimizacion de modelos de aprendizaje profundo que busca reducir el tamano y el con- sumo de recursos computacionales de un modelo sin compro- meter significativamente su precision. La idea es convertir los parametros del modelo (usualmente almacenados en formato de punto flotante de 32 bits, float32) a representaciones de menor precision, como int8, int4 o incluso int1, dependiendo del nivel de compresion deseado. Esto permite ejecutar modelos de gran tamano en hardware con recursos limitados (por ejemplo, dispositivos moviles o microcontroladores).III-A. Ejemplo contextual Un modelo como LLaMA 2 posee mas de 70 mil millones de parametros, lo que equivale a aproximadamente 28 GB solo para almacenarlos en disco. Cargar ese modelo en memoria seria inviable sin una GPU especializada, por lo que la quantization se convierte en una alternativa para reducir el tamano y mantener la funcionalidad. IV. REPRESENTACION NUMERICA IV-A. Numeros enteros Los computadores representan los numeros utilizando se- cuencias de bits. Con N bits se pueden representar2nvalores distintos. Por ejemplo, con 3 bits se pueden representar los numeros del