calidad del terreno, el grado de vision disponible y la experiencia total del conductor. A partir de estos parametros, la red aprende a identificar patrones que permiten estimar la probabilidad de que ocurra una colision bajo determinadas Figura 1. Modelo de red neuronal preentrenado para la clasificacion de eventos de colision. 2 Cuadro II EJEMPLO SIMPLIFICADO DE TOKENIZACION Palabra Token ID Numerico Los los 105 LLM llm 2124 aprenden aprenden 893 patrones patrones 5749 condiciones. El uso de modelos preentrenados en este contexto facilita una generalizacion mas robusta y una convergencia mas rapida durante el proceso de entrenamiento, lo cual resulta ventajoso en escenarios donde los datos etiquetados son limitados [4]. III-B. Tokenizacion En el procesamiento del lenguaje natural, cada palabra, signo o simbolo debe transformarse en una representacion numerica para que pueda ser comprendida y procesada por los modelos de lenguaje. Este proceso se conoce comotoke- nizacion, y consiste en dividir el texto en unidades minimas denominadastokens, que pueden corresponder a palabras, subpalabras o incluso caracteres individuales. A cada token se le asigna un identificador numerico unico dentro de un vocabu- lario previamente definido, lo que permite representar oracio- nes completas como secuencias de numeros. Existen diversas estrategias de tokenizacion, como la basada en subpalabras (Byte Pair EncodingoWordPiece), que buscan equilibrar la eficiencia del vocabulario con la capacidad del modelo para manejar palabras desconocidas o de diferentes idiomas [5]. La Tabla II muestra un ejemplo simplificado del proceso de