(in- context learning). Multitarea: realizan traduccion, clasificacion, codifica- cion, analisis o dialogo sin requerir reentrenamiento. IV-C. Limitacion de los modelos de lenguaje Alucinaciones:generan respuestas convincentes pero incorrectas o inventadas. Memoria limitada:no recuerdan interacciones pasadas mas allade su ventana de contexto. Conocimiento estatico:su informacion proviene de los datos de entrenamiento. Costos computacionales:requieren grandes recursos para entrenamiento e inferencia. V. RETRIVAL-AUGMENTEDGENERATION(RAG) El enfoque de Recuperacion Aumentada de Generacion (Retrieval-Augmented Generation, RAG) combina la potencia generativa de los modelos de lenguaje de gran escala (LLM) con un modulo de recuperacion de informacion externa, cono- cido comoretriever. Este componente permite inyectar cono- cimiento relevante proveniente de bases de datos o colecciones de documentos en el momento de la consulta, ampliando asila capacidad del modelo para generar respuestas mas precisas, actualizadas y fundamentadas en evidencia. De esta manera, el sistema integra razonamiento generativo con recuperacion informativa, superando las limitaciones de los LLM entrenados unicamente con conocimiento estatico [1]. V-A. Ingesta y Chunking El primer paso en la construccion de un sistema de Recupe- racion Aumentada de Generacion (RAG) consiste en preparar los documentos que serviran como fuente de informacion. Para ello, el texto se segmenta en fragmentos manejables denominadoschunks, que suelen tener una longitud entre 200 y 500 tokens, con el fin de preservar la coherencia semantica y facilitar la recuperacion eficiente de informacion relevante. 4 Posteriormente, cada fragmento se transforma en un vector mediante un modulo deembeddings, el cual codifica su signi- ficado semantico