para problemas linealmente separables, pero no puede resolver problemas no lineales (ej. XOR). B. Redes profundas y arquitecturas comunes El deep learning usa redes con muchas capas: perceptrones multicapa (MLP), redes convolucionales (CNN) y redes re- currentes (RNN/LSTM/Transformer). Cada arquitectura esta orientada a distintos tipos de datos: •CNN: imagenes y datos con estructura espacial. •RNN / LSTM: secuencias temporales y texto (historicamente). •Transformers: atencion y modelado de dependencias a larga distancia (estado del arte en NLU y NLG). C. Yann LeCun y las CNN Yann LeCun fue pionero en redes convolucionales (LeNet) y en su aplicacion al reconocimiento de digitos. Las CNN aprenden filtros que detectan caracteristicas locales (bordes, texturas) y luego construyen representaciones de alto nivel mediante capas sucesivas. Fig. 3. Esquema de una red convolucional V. D ATOS :EL CORAZON DE LA IA A. Calidad y preprocesamiento Los datos deben ser: •Representativos del problema real. •Limpios : sin errores obvios (p. ej. mezcla Cel- sius/Fahrenheit). •Balanceados o bien tratados para evitar sesgos. •Steven Pacheco 2025 - Si tenemos mal los datos, mala es la salida de nuestra funcion Tecnicas comunes: normalizacion, imputacion (media/mediana), deteccion y tratamiento de outliers, ingenieria de caracteristicas y enriquecimiento. B. Sesgos y equidad Los datasets reflejan las desigualdades del mundo real. Un modelo entrenado con datos sesgados puede perpetuar discriminaciones. Ejemplos practicos: •Reconocimiento facial con peor desempeño en ciertos grupos demograficos. •Modelos de credito que penalizan poblaciones subrepre- sentadas. Buenas practicas: auditorias de sesgo,