nalmente. w←w−α∂L ∂w Figura 4. Stochastic Gradient DescentC3. Mini-batch Gradient Descent: ElMini-batch Gra- dient Descent combina las estrategias anteriores: calcula la gradiente sobre batches de tamaño intermedio. Ventajas: Reduce el ruido respecto a SGD y es mas estable. Mas eficiente que Batch GD. Mejora la explotacion de hardware (vectorizacion, GPUs). Figura 5. Mini-batch Gradient Descent REFERENCIAS [1] Belcak, P., et al, ”Small Language Models are the Future of Agentic AI”2025. [2] E. Brynjolfsson et al., “Canaries in the Coal Mine? Six Facts about the Recent Employment Effects of Artificial Intelligence” 2025.